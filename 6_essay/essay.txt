Title: Design sous artifice

----

Date: 2023-02-01

----

Text:

<a id="top" name="essay">&nbsp;</a>
# Design sous artifice
La création au risque du *machine learning*
[Anthony Masure](https://www.anthonymasure.com)

##

- [Introduction](#introduction)
- [Contexte](#contexte)
	- [Le jeu de l'imitation d'Alan Turing](#le-jeu-de-l-imitation-d-alan-turing)
	- [Des boîtes noires aux premiers neurones artificiels](#des-boites-noires-aux-premiers-neurones-artificiels)
	- [Le moment cybernétique de la psychanalyse](#le-moment-cybernetique-de-la-psychanalyse)
	- [Approches symboliques et connexionnistes : deux voies pour les IA](#approches-symboliques-et-connexionnistes-deux-voies-pour-les-ia)
	- [Le *deep learning* comme héritage de la cybernétique comportementaliste](#le-deep-learning-comme-heritage-de-la-cybernetique-comportementaliste)
- [Implication politiques](#implication-politiques)
	- [Renforcer le pouvoir](#renforcer-le-pouvoir)
	- [Assister ou asservir](#assister-ou-asservir)
	- [Stéréotyper les méthodes de conception](#stereotyper-les-methodes-de-conception)
	- [Imiter et uniformiser](#imiter-et-uniformiser)
	- [Confondre création et production](#confondre-creation-et-production)
- [Potentialités créatives](#potentialités-créatives)
	- [Révéler les dynamiques de standardisation](#reveler-les-dynamiques-de-standardisation)
	- [Responsabiliser l'injonction à la simplicité](#responsabiliser-l-injonction-a-la-simplicite)
	- [Jouer avec les aléas et limites de la prédiction](#jouer-avec-les-aleas-et-limites-de-la-prediction)
	- [Traduire des codes culturels](#traduire-des-codes-culturels)
	- [Inventer de nouveaux modes de collaboration](#inventer-de-nouveaux-modes-de-collaboration)
- [Conclusion](#conclusion)
- [Bibliographie](#bibliographie)
- [Illustrations](#illustrations)
- [Crédits](#crédits)
- [Notes](#notes)

<a name="introduction"></a>
### [↑](#essay) Introduction

> « Nous avons alimenté le système avec un ensemble de données de 15 000 portraits peints entre le XIV^e^ siècle et le XX^e^ siècle. Le générateur crée une nouvelle image à partir de ce jeu de données, puis le discriminateur tente de repérer la différence entre une image créée par l'humain et une image créée par le générateur. Le but est de tromper le discriminateur en lui faisant croire que les nouvelles images sont des portraits réels. » (Christie's, 2018)

(image: illustrations/Fig1.png caption: Fig.1 - Portrait d’Edmond Belamy)

Cette étrange mise en scène de programmes informatiques se dupant les uns les autres décrit le processus de conception du *Portrait d'Edmond Belamy* <a name="fig-1">[\[Fig. 1\]](#ref-fig-1)</a> (Collectif Obvious[^1], 2018), un tableau généré par une « intelligence artificielle »[^2]. Vendu par Christie's pour la somme record de 432 500 dollars, ce dernier a attiré l'attention du grand public sur les technologies du *machine learning* (« apprentissage automatique ») et a ouvert (select:1)un débat sur la place des artistes et designers dans un monde où des machines seraient capables de créer.(deselect:1) Cette peinture s'inscrit dans la lignée d'initiatives comme *The Next Rembrandt* (2016) <a name="fig-2">[\[Fig. 2\]](#ref-fig-2)</a>, une opération de communication initiée par l'agence publicitaire J. Walter Thompson et (select:2)prenant la forme d'une œuvre « inédite » générée à partir(deselect:) de la modélisation du style de 346 tableaux de l'artiste du même nom (ING, 2020). Quelques années plus tard, des programmes comme DALL·E (2021) produisent des images (illustrations, etc.) à la demande, à partir de commandes textuelles (« *prompts* »), et posent à nouveau la question du remplacement de l'humain par la machine, faisant fi des dynamiques économiques et politiques sous-tendant ces technologies.

(image: illustrations/Fig2.png caption: Fig.2 - The Next Rembrant, Microsoft, J. Walter Thompson)

Au tournant des années 2010, les progrès du *machine learning* --- et plus précisément ceux du *deep learning* (« apprentissage profond ») --- ont rendu possible la production de programmes informatiques qui ne sont plus écrits par des êtres humains mais par des machines. S'appuyant sur l'analyse de larges jeux de données agrégées en ligne (textes, images, vidéos, etc.), le *deep learning* s'est révélé plus efficace que la programmation « traditionnelle » pour traiter des tâches complexes comme la reconnaissance de formes ou l'analyse de textes. Transposées à l'art et au design, ces technologies soulèvent des questions complexes liées aux notions de vérité, d'autorité et d'humanité. Pour examiner ces enjeux, il importe tout d'abord de prendre de la distance avec l'expression générique et fantasmée d'« intelligence artificielle », qui a pour revers de masquer ses conditions techniques, tant matérielles (dissimulation des matières premières et personnes nécessaires à leur fonctionnement) que logicielles (effet « boîte noire ») (Masure, 2019, p. 31-46). Leur analyse est nécessaire pour mettre en évidence le fait que le modèle dominant (dans les *mass media*) de l'apprentissage automatique, celui du *deep learning*, n'est pas pensé pour être intelligible mais pour être efficace. Ce paradigme de la rentabilité a pour conséquence d'engendrer une société où prime le rendement et non pas l'inventivité, le doute et l'attention au contexte --- autant de qualités essentielles dans les champs de la création. La polarisation des médias sur le possible remplacement de l'humain par l'IA ne permet donc pas de poser la question essentielle, objet de cet essai : quel est le spectre des implications actuelles et potentielles du *machine learning* pour les pratiques de design ?

Pour mieux saisir en quoi l'apprentissage automatique participe de ce que nous proposons d'appeler un « design sous artifice » --- à savoir une subversion insidieuse de ses principes historiques (s'opposer à la baisse de qualité des productions en série) ---, cet ouvrage propose, dans une première partie (« [Contexte](#contexte) »), d'examiner les théories psychologiques qui sous-tendent leur fonctionnement. Cette prise de recul historique éclaire, dans la deuxième partie du livre (« [Implication politiques](#implication-politiques) »), la volonté de réduire le design à une suite de modèles schématiques --- une voie à sens unique où le processus créatif peut être automatisé et confié à des machines. En normalisant les pratiques créatives, les intelligences artificielles contemporaines s'inscrivent en effet dans la longue histoire des logiciels de création et de la démocratisation de l'accès aux ordinateurs.

Pour éviter que le travail des designers se réduise à des logiques normatives ou statistiques, la méthode de recherche mobilisée[^3] consiste, dans l'ordre : à dégager de la notion déterminant le processus de production (l'intelligence artificielle) des concept sous-jacents (automatisation, imitation, efficience), à établir la généalogie de cette notion *via* l'analyse de multiples discours (des concepteur·trices, des entrepreneur·euses, des communicant·es, des marketeur·euses, etc.), et à synthétiser l'histoire et les discours de projets de design pour en dégager les enjeux philosophiques sous-jacents.

À rebours de la volonté de modéliser l'activité du design sous forme de chaînes logiques (diagrammes, schémas, *timelines*, etc.), il ne s'agit donc pas de dire aux designers ce qu'il convient de faire, mais de leur fournir, dans leur démarche même, des entrées critiques leur permettant d'analyser l'existant ou ce qu'ils·elles sont en train d'inventer. Nous montrons ainsi, dans la troisième et dernière partie de l'ouvrage (« [Potentialités créatives](#potentialités-créatives) »), que les technologies du *machine learning* déplacent et redéfinissent les notions de création et de subjectivité en automatisant un certain nombre de tâches habituellement dévolues au design. Par exemple, l'entreprise Zalando travaille avec Google depuis 2016 pour prédire les tendances de la mode, et des logiciels comme TheGrid.io (2014), Wix ADI (2016) ou Adobe Sensei (2016) visent à fluidifier la conception d'interfaces pour le meilleur et pour le pire. De nouvelles formes de travail avec les machines sont en train d'émerger, comme le montrent des artistes et designers avec lesquel·les Alexia Mathieu (responsable du Master Media Design de la HEAD -- Genève) s'est entretenue dans le cadre d'un projet de recherche associé à cet essai[^4], et dont des extraits sont répartis dans ses différents chapitres.

Ce trajet entre implications politiques et potentialités créatives nuance une partition trop simpliste entre risques d'une part et opportunités de l'autre. Le renforcement des structures du pouvoir, par exemple, est de façon cynique à la fois un risque pour des populations minorisées et une opportunité économique. Plus fondamentalement, le *machine learning* engendre un certain nombre de crises qui obligent à repenser des notions comme la gouvernance, la responsabilité, ou la centralité de l'humain et du masculin. L'art et le design, par leurs ancrages dans l'esthétique, la technique ou la spéculation, ont ainsi un rôle à jouer pour révéler des dynamiques de standardisation et proposer d'autres rapports aux machines que leur instrumentalisation.

<a name="contexte"></a>
### [↑](#essay) Contexte

<a name="le-jeu-de-l-imitation-d-alan-turing"></a>
#### Le jeu de l'imitation d'Alan Turing

(select:3)Les relations entre les ordinateurs et la pensée hantent l'informatique depuis ses débuts. Publié en 1945 par l'ingénieur Vannevar Bush, l'article « As We May Think » (« Comme nous pourrions penser ») envisage, sous forme de fiction, que des appareils puissent augmenter les capacités intellectuelles pour éviter à l'humanité de basculer dans un conflit nucléaire meurtrier ; la délégation d'opérations intellectuelles aux machines n'a pas vocation à remplacer les humains, mais doit permettre de les « déprogrammer » de tâches fastidieuses(deselect:) :

« Un mathématicien n'est pas un être humain qui peut facilement manipuler des chiffres. Il n'est pas non plus une personne qui peut facilement résoudre des équations \[\...\]. C'est essentiellement un expert d'une logique symbolique avancée, et plus précisément une personne dotée d'intuition face aux choix des techniques de manipulation qu'il emploie. \[\...\] Dès qu'un processus logique de pensée est employé --- c'est-à-dire dès qu'une logique de pensée opère avec une routine installée ---, il y a une opportunité pour la machine. » (Bush, 1945, p. 101-108)

En associant la notion d'intelligence à la sélection et à l'intuition --- et non pas au traitement d'informations ---, Vannevar Bush entrevoit des questions qui seront prolongées par le mathématicien Alan Turing. Avec son concept de « machine universelle » (Turing, \[1936\] 1995), il pose les bases de la programmation informatique, à savoir une suite d'instructions logiques exécutées par une machine en vue d'atteindre un objectif déterminé. En 1950, Turing et les équipes du National Physical Laboratory rendent public l'Automatic Computing Engine, une des premières machines programmables. Poussant la vieille distinction philosophique entre le corps et l'esprit (*hardware/software*[^5]) à son paroxysme, Turing en vient à considérer explicitement la possibilité d'un cerveau électronique. Dans son article « Les ordinateurs et l'intelligence » (Turing, \[1950\] 1995) publié la même année, il se demande à quelles conditions une machine électronique pourrait être douée d'intelligence et, le cas échéant, comment le reconnaître du point de vue humain. L'apport théorique de Turing consiste alors à remplacer la question « Les machines peuvent-elles penser ? » par : « Un ordinateur peut-il tenir la place d'un être humain dans un jeu basé sur l'imitation ? ». Dans cette situation fictive, Turing considère que la machine fait preuve d'une intelligence « humaine » si elle parvient à déjouer l'interrogateur au-delà du taux aléatoire de 50 % (Jorion, 2000). Selon ce modèle devenu canonique et repris dans de nombreux films de science-fiction (*Blade Runner*, *Ex Machina*, etc.), la machine est envisagée sous l'angle de la simulation --- peu importe si personne n'est en mesure de comprendre le fonctionnement interne de la machine :

« Nous voulons \[\...\] accepter la possibilité \[\...\] qu'une équipe d'ingénieurs puisse construire une machine qui fonctionne, mais dont les modalités de fonctionnement ne peuvent être décrites de manière satisfaisante par ses concepteurs, parce qu'ils ont appliqué une méthode en grande partie expérimentale. » (Turing, \[1950\] 1995, p. 139)

La prise de distance avec l'intelligibilité d'un système technique au bénéfice de son efficacité (l'effet « boîte noire ») fait écho au champ de la cybernétique, dont les principes ont déterminé de nombreux systèmes contemporains de calcul, d'interfaces, et d'interaction mis en œuvre par des ingénieur·euses et des designers.

<a name="des-boites-noires-aux-premiers-neurones-artificiels"></a>
#### [↑](#essay) Des boîtes noires aux premiers neurones artificiels

(select:15)La naissance de la cybernétique est généralement reliée à la publication de l'ouvrage *La cybernétique*. *Information et régulation dans le vivant et la machine* du mathématicien Norbert Wiener(deselect:) (Wiener, \[1948\] 2014). Cette « science du contrôle » (*kubernétès*) prend racine dans la balistique militaire (permettant d'ajuster la trajectoire d'un missile en temps réel, sans intervention humaine), ainsi que dans l'optimisation des flux de ravitaillements aériens. Elle va rapidement investir d'autres champs d'applications pour devenir un paradigme mental pouvant concerner l'individu, voire l'ensemble de ses relations sociales (Klein *et al.*, \[2013\] 2015). Si l'on associe couramment le concept de « boîte noire » à la cybernétique, celui-ci vient plus précisément des théories comportementalistes. À la suite des expériences sur les « réflexes conditionnels » d'Ivan Pavlov (1849-1936), figure la plus célèbre du comportementalisme, les psychologues John Broadus Watson (Watson, 1913, p. 158-177) et Burrhus Frederic Skinner développent le « behaviorisme », une méthode permettant d'étudier les relations statistiques entre l'environnement et le comportement en faisant fi du psychisme humain. Les processus inobservables s'effectuent dans une *black box*, qui ne constitue pas un objet de recherche car seule compte l'observation de « comportements manifestes » (un stimulus en réaction à un bruit, etc.). Dans la vision comportementaliste de l'apprentissage, l'apprenant est semblable à une boîte noire car on ne sait pas --- et il n'y a pas besoin de savoir --- ce qui se passe à l'intérieur. L'individu est le seul résultat de son environnement : il suffit d'analyser ses entrées (*inputs*) et sorties (*outputs*).

Si la cybernétique de Norbert Wiener reprend l'idée de Von Neumann qu'une machine (un ordinateur) puisse être comparable au cerveau humain *via* cette idée de boîte noire, elle introduit également le concept de « rétroaction » (*feedback*) (Rosenblueth *et al.*, \[1943\] 1995, p. 44-56) qui n'existe pas dans le comportementalisme, à savoir l'ajustement dynamique des données d'entrée et de sortie ayant pour objectif le contrôle d'une situation donnée. Dans les pays francophones, si on a tendance à agglomérer les approches comportementalistes et cognitivistes (d'où l'expression de TCC pour « thérapies cognitivo-comportementales »), aux États-Unis le cognitivisme, né à partir de la cybernétique, est vu comme une critique du comportementalisme. Ainsi, s'appuyant sur la cybernétique, les théories cognitivistes vont reprendre le paradigme de l'*input*/*output*, non plus pour dire que le psychisme est une boîte noire, mais pour étudier la structure du système responsable des différences entre les entrées et les sorties. Définie par Wiener comme une « théorie entière de la commande et de la communication, aussi bien chez l'animal que dans la machine » (Wiener, \[1948\] 2014, p. 70), la cybernétique historique ne peut donc se réduire ni à une simple évolution des mathématiques, ni à une logique comportementaliste.

Selon le philosophe Pierre Cassou-Noguès, la cybernétique va prolonger les travaux de Turing vers une logique de simulation des neurones du cerveau humain (Cassou-Noguès, 2009, p. 141-159). Après avoir établi les bases de l'architecture interne de l'ordinateur (séparation entre l'unité arithmétique et logique, l'unité de contrôle, la mémoire vive, la mémoire de masse, les dispositifs d'entrées-sorties), Von Neumann en vient à travailler sur le concept d'« automate cellulaire » --- une simulation de processus d'auto-reproduction à la frontière de l'informatique et de la biologie. Réunis en partie dans l'ouvrage posthume *L'ordinateur et le cerveau* (Von Neumann, \[1958\] 1996), ses conférences et articles permettent de préciser le passage du vivant à une machine prenant la forme d'un « réseau neuronal », soit donc une préfiguration explicite --- du moins dans le vocabulaire --- des « réseaux neuronaux » du *deep learning* :

« Tout fonctionnement, en ce sens, s'il peut être défini logiquement, exactement, sans ambiguïté en un nombre fini de mots, peut également être réalisé par un tel réseau \[de neurones\] formel. » (Von Neumann, \[1948\] 2009, p. 309)

<a name="le-moment-cybernetique-de-la-psychanalyse"></a>
#### [↑](#essay) Le moment cybernétique de la psychanalyse

Alors que l'on comprend la cybernétique comme une réduction mathématique (formelle) du psychisme humain, une étude plus fine montre au contraire comment celle-ci va être reprise par le psychiatre Jacques Lacan pour refonder la psychanalyse en envisageant la cybernétique au-delà de la « théorie de la communication » de Shannon et Weaver et des méthodes comportementalistes (Saint-Jevin, 2017). Dans le modèle de la « machine universelle » de Turing, l'arrêt d'une machine ne peut pas être calculé ; le calcul ne peut exister que parce qu'il est possible de délimiter une zone incalculable. Autrement dit, pour Lacan, le sens ne peut émerger que de l'arrêt (de la coupure) d'une machine : « Ce qui \[\...\] donne sa signification \[au monde des signes\] est le moment où nous arrêtons la machine. » (Lacan, \[1954-1955\] 1978, p. 328) Cette notion d'« état de la machine » est décisive. Contrairement à la machine universelle de Turing qui ne peut pas contenir sa propre fin (son arrêt), l'informatique « effective » a dû intégrer le principe du *boot* (amorçage) pour permettre de remettre la machine à un état zéro, « vierge de tout calcul » (Saint-Jevin, 2017, p. 761-773). Si, pour le sujet, le sens émerge de l'arrêt de la machine, une machine « totale » (conçue dans une logique de fonctionnement continu) ne pourrait donc pas être créative, c'est-à-dire faire advenir de nouvelles significations.

(select:4)La lecture psychanalytique de la cybernétique sera rapidement marginalisée par la montée en puissance des approches comportementalistes qui n'auront de cesse d'accroître leur emprise sur l'ensemble des activités humaines. En 1950, la même année que l'article de Turing sur les machines intelligentes, Wiener s'inquiétait du risque d'un progrès technique pouvant mener à un « usage inhumain des êtres humains » (Wiener, \[1950-1954\] 2014), qui se prolonge aujourd'hui dans la prolifération d'objets et de systèmes techniques dont la finalité est de fonctionner en continu, ce qui laisse donc l'individu en dehors du sens.(deselect:)

<a name="approches-symboliques-et-connexionnistes-deux-voies-pour-les-ia"></a>
#### [↑](#essay) Approches symboliques et connexionnistes : deux voies pour les IA

(select:16)La simulation des neurones humains ouvre la voie à une première approche de l'intelligence artificielle, qualifiée de « connexionniste »(deselect:) (Warren McCulloch, Frank Rosenblatt, etc.) et basée sur la psychanalyse lacanienne, dans laquelle des ingénieurs s'appuient sur des « représentations » de neurones connectés par des synapses artificielles (le neurologue Sigmund Freud étant le précurseur de la notion de « connexion » entre les neurones) (Saint-Jevin, 2019, p. 99-177). À cette approche « connexionniste » s'oppose la logique « symbolique » (Marvin Minsky, Seymour Papert, Allen Newell, Herbert A. Simon, etc.[^6]), qui propose de modéliser les « lois universelles » de la pensée par la manipulation de symboles (Cardon *et al.*, 2018). L'expression d'« intelligence artificielle » est forgée en 1955 par le mathématicien John McCarthy. Selon McCarthy et ses collègues partisans de l'approche symbolique (Marvin Minsky, Nathaniel Rochester et Claude Shannon), « tous les aspects de l'apprentissage ou toute autre caractéristique de l'intelligence peuvent en principe être décrits avec une telle précision qu'une machine peut être construite pour les simuler » (McCarthy *et al.*, \[1955\] 2006). La critique des capacités de calcul des « perceptrons » (ancêtres des réseaux de neurones) par le chercheur cognitiviste Marvin Minsky (Minsky et Papert, 1969) entraîne une perte de confiance des investisseurs et fait plonger l'IA dans un « premier hiver » de 1974 à 1980.

En 1982, le physicien John Hopfield démontre qu'un « réseau neuronal » peut apprendre et traiter de l'information d'une manière totalement inédite. Encore marginale, cette approche resurgira suite au « second hiver » de l'IA (1987-1993) correspondant à la chute des promesses de l'IA symbolique, celle des « systèmes experts » (outils d'aide à la décision censés imiter des capacités cognitives). (select:5)À la fin des années 1980, les recherches fédérées par l'informaticien Yann Le Cun vont rouvrir l'axe des réseaux de neurones, qui va se révéler plus efficace que l'approche symbolique.(deselect:) Appliquée par exemple à la reconnaissance automatique des codes postaux manuscrits fournis par la poste américaine (Le Cun *et al.*, 1989, p. 541-551), la logique neuronale réussit à prendre en charge l'ensemble de l'opération, depuis la normalisation des caractères typographiques jusqu'à leur classification finale. Comme le notent les chercheurs Dominique Cardon, Jean-Philippe Cointet et Antoine Mazières, c'est l'explosion des données caractéristiques de la massification des usages numériques et du *big data* des années 2010 qui assoit pour de bon l'approche neuronale. Celle-ci se révèle très performante pour traiter les domaines aussi généralistes que le traitement du signal, de la voix, de la parole ou du texte, mais surtout pour faire face à de nouveaux défis « comme la détection de *spams*, les techniques de filtrage collaboratif utilisées pour la recommandation, la prédiction de stock, la recherche d'information ou l'analyse des réseaux sociaux » (Cardon *et al.*, 2018).

Les technologies de l'approche connexionnistes vont alors s'imposer jusqu'à être confondues, dans l'esprit du grand public, avec la notion beaucoup plus large d'intelligence artificielle --- créant ainsi une étrange boucle dans l'histoire sociale des sciences et des techniques où les « chercheur·euses, s'appuyant sur l'arrivée de données massives et la démultiplication des capacités de calcul, ont entrepris de reformuler le projet de l'IA symbolique en renouant avec l'esprit des machines adaptatives et inductives de l'époque de la cybernétique » (Cardon *et al.*, 2018). Cependant, comme nous allons le voir, le retour à l'approche connexionniste opéré par les réseaux de neurones des années 1980 ne va pas s'appuyer sur le caractère psychanalytique de la cybernétique historique, mais va au contraire s'ancrer dans les vieilles théories du comportementalisme puisque l'horizon méthodologique du *machine learning* est d'augmenter l'efficacité du résultat et non pas d'examiner le fonctionnement du psychisme.

<a name="le-deep-learning-comme-heritage-de-la-cybernetique-comportementaliste"></a>
#### [↑](#essay) Le *DEEP LEARNING* comme héritage de la cybernétique comportementaliste

Le terme de *deep learning* (« apprentissage profond ») est forgé en 2006 par l'ingénieur Geoff Hinton (Hinton *et al.*, 2006, p. 1527-1554). (select:11)Dérivé du *machine learning*, le *deep learning* désigne une méthode où la machine a pour objectif d'« apprendre par elle-même » --- contrairement à la programmation « traditionnelle » de la logique symbolique où elle se contente d'exécuter des règles prédéterminées par des humains.(deselect:) Le *deep learning* se base sur un réseau de « couches » de neurones artificiels s'inspirant du cerveau humain, lesquels vont traiter des données complexes *via* des processus de « rétropropagation » (Kurenkov, 2015). Les données de départ sont essentielles : plus le système en accumule, plus il est censé être performant. Pour être *computées*, celles-ci doivent tout d'abord subir un travail d'atomisation et de « désassociation » afin d'en faire des entités numériques normalisées sous forme de coordonnées géométriques (des « vecteurs »). Les couches de neurones permettent ainsi de découper une tâche complexe en sous-catégories vectorielles (non signifiantes pour l'humain), l'idéal étant d'automatiser l'ensemble du processus pour viser une méthode dite « non supervisée ». Le système apprend par exemple à reconnaître les lettres avant de s'attaquer aux mots dans un texte, ou détermine s'il y a un visage sur une photo avant de découvrir de quelle personne il s'agit. À chaque étape, les « mauvaises » réponses sont éliminées et renvoyées vers les niveaux en amont pour aligner le modèle mathématique. En comparant les éléments bruts (*inputs*) avec des jeux de données « étiquetées » (*outputs*), le réseau de neurones ajuste automatiquement son processus de traitement pour écrire un programme informatique de plus en plus performant. Avec le *deep learning*, ce ne sont plus des opérateurs humains qui élaborent les règles de traitement des données à base de petits *datasets* soigneusement calibrés, mais bien des machines à qui l'on confie « le soin de produire des prédictions pertinentes en apprenant des données » (Cardon *et al.*, 2018).

« Ce qui caractérise l'architecture de ces machines est que leur couplage avec l'environnement (*le monde*) est si intime qu'il n'est pas nécessaire de doter leur calculateur d'une agentivité propre. La proposition de la cybernétique est d'en faire une simple boîte noire apprenante et associationniste dont l'horizon se règle en mesurant l'écart (*l'erreur*) entre le monde et le comportement de la machine. » (Cardon *et al.*, 2018)

Cette citation, au vu de ce que nous avons vu précédemment, montre qu'avec le *deep learning* une confusion s'est installée entre le comportementalisme et le cognitivisme, puisque la cybernétique apparaît historiquement comme une contestation de la notion de boîte noire. Celle-ci reprend certes les méthodes du comportementalisme (l'étude des comportements), mais a pour objectif d'élaborer des hypothèses sur les façons dont les comportements s'effectuent. Cela montre que le *deep learning*, s'il naît du cognitivisme, se rapproche davantage du comportementalisme en allant à l'encontre des principes historiques de la cybernétique (la rétropropagation des couches neuronales n'est pas équivalente à la rétroaction du *feedback*).

<a name="implication-politiques"></a>
### [↑](#essay) Implications politiques

<a name="renforcer-le-pouvoir"></a>
#### Renforcer le pouvoir

(select:6)L'étude historique des intelligences artificielles, depuis leurs racines cybernétiques jusqu'à leur reformulation comportementaliste dans le *deep learning*, montre que ce dernier participe majoritairement d'une vision utilitariste du corps social. Bien qu'il se révèle très puissant pour traiter de larges jeux de données, le *deep learning* soulève plusieurs problèmes majeurs(deselect:) :

• De façon générale, loin d'être une technologie neutre et en retrait des structures de pouvoir (États, entreprises, etc.), le *deep learning* les prolonge et les renforce. Les exemples d'applications « immorales » des IA ne manquent pas, comme le profilage des goûts et génération de contenus personnalisés (Netflix, 2017), l'analyse de « parcours utilisateurs » au sein de contextes marchands (*New York Times*, *Dynamic Meter*, 2022), ou la détection de passagers ivres (Uber, 2018), et participent d'une pensée « techno-solutionniste » (Morozov, \[2013\] 2014), c'est-à-dire comprenant la technologie comme la solution à tout problème sociopolitique. Les IA contemporaines s'appuient sur les mêmes bases idéologiques que l'informatique dominante, à savoir une rationalisation du sensible (Klein *et al.*, \[2013\] 2015) et une modélisation des existences. Dans son *Contre-atlas* *de l'intelligence artificielle* (2021), la chercheuse Kate Crawford note que « cet aplatissement épistémologique de la complexité en un signal net à des fins de prédiction est aujourd'hui une logique centrale de l'apprentissage automatique » (Crawford, \[2021\] 2022). De même, le sociologue Dominique Cardon fait remarquer, ironiquement, que « les algorithmes qui se disent prédictifs ne le sont pas parce qu'ils seraient parvenus à entrer dans la subjectivité des personnes pour sonder leurs désirs ou leurs aspirations. Ils sont prédictifs parce qu'ils font constamment l'hypothèse que notre futur sera une reproduction de notre passé » (Cardon, 2015, p. 70).

• En raison du fait qu'ils sont principalement constitués de contenus collectés en ligne, les jeux de données du *deep learning* emportent et renforcent des biais sociaux, notamment vis-à-vis de la représentation des genres et des personnes autochtones et racisées (BIPOC). Les exemples ne manquent pas : une police cherchant à prédire les comportements à risque (*Predictive Policing*, 2011), un tribunal américain s'appuyant sur des statistiques pour quantifier les risques de récidive et qui juge plus durement les BIPOC (Department of Justice, National Institute of Corrections, 2016), un robot recruteur discriminant les femmes (Amazon, 2018), ou encore des systèmes de reconnaissance faciale visant à déterminer le genre d'une personne en ligne (Face++, 2018) ou au *check-in* d'un aéroport (Détroit, USA, 2018) <a name="fig-3">[\[Fig. 3\]](#ref-fig-3)</a>. Ces mécanismes de discrimination « embarquée » (*embedded*), d'autant plus puissants qu'ils sont invisibles, peuvent avoir de lourdes conséquences sur des populations déjà marginalisées. Selon Kate Crawford et l'artiste Trevor Paglen, de vastes jeux de données comme ImageNet (2006) « ne sont pas simplement des matières premières pour alimenter les algorithmes, mais des interventions politiques \[\...\]. Toute l'entreprise de collecte d'images, de leur catégorisation et de leur étiquetage est en soi une forme de politique, pleine de questions sur qui peut décider de la signification des images et quels types de travail social et politique ces représentations effectuent. » (Crawford et Paglen, 2019 ; Keller, Gunti et Amoser, 2021, p. 83) La demande d'éthique adressée au *machine learning*, à supposer qu'elle puisse être modélisée, peine à s'aligner aux diverses régulations et valeurs des États-nations. Comment comparer des IA chinoises, américaines, arabes ou européennes ? Faut-il œuvrer à « décoloniser » leurs *patterns* ? (Lovink, 2022)

(image: illustrations/Fig3.png caption: Fig.3 - check-in d'un aéroport)

• La plupart des chercheur·euses en *machine learning* travaillent pour les GAFAM (Google, Amazon, Facebook, Apple, Microsoft) et leurs avatars asiatiques (BATX : Baidu, Alibaba, Tencent et Xiaomi), seuls acteurs à même de les rémunérer, de collecter des données et de les computer, ce qui ne fait que renforcer leur hégémonie. Communément reconnu comme l'inventeur de l'« apprentissage profond », l'ingénieur Yann Le Cun, sous la houlette de Facebook depuis 2013 (la même année où son directeur de post-doctorat, Geoffrey Hinton, rejoint Google), développe par exemple des traitements d'analyse d'images et de conversations renforçant l'« architecture toxique » (Ertzscheid, 2018) de cette plateforme publicitaire aux deux milliards d'utilisateur·trices. Comme le notent les membres du groupe de travail « AI Anarchies », on peut légitimement douter de la capacité de grands groupes à œuvrer pour le bien commun : « L'éthique de l'IA s'apparente à une promesse tiède d'auto-réguler la Big Tech tout en maintenant le cap vers un avenir qu'elle a conçu. Pendant ce temps, les systèmes d'apprentissage automatique se développent à grande échelle. » (Herrmann et Vukajlović, 2022)

• En raison du caractère opaque des technologies du *deep learning*, personne, y compris les programmeur·euses, ne sait exactement comment fonctionnent les programmes ainsi générés. Appelant à davantage d'intelligibilité technique, le designer Boyd Rotgans note que « le défi que nous devons résoudre est d'être transparent sur la façon dont une décision a été prise, ou au moins d'être en mesure de dire quelles données sont entrées et quels résultats en sont sortis. Si vous achetez un produit au supermarché, vous pouvez lire ce qu'il contient et comment il a été produit. Si le fossé entre les humains et les technologies est trop grand, cela devient effrayant. » (<a class="interview" style="cursor:pointer" onclick="openWindow('Boyd Rotgans', 'interviews/Boyd-Rotgans', event)">Mathieu</a>, 2022) Ce paradigme de l'opacité engendre un problème de responsabilité, puisqu'il devient impossible d'imputer la faute à quelqu'un ou quelque chose : qui ou quoi faut-il blâmer quand un programme « tue » une personne hospitalisée pour avoir formulé un mauvais diagnostic, ou quand une voiture « autonome » renverse un humain ? Si certain·es pensent ainsi qu'il est possible de créer du *deep learning* « explicable », cette transparence nécessitera de produire des surcouches techniques, elles-mêmes sujettes à caution. De façon plus générale, le sociologue Benjamin Bratton voit dans la multiplication et la superposition des couches (*stacks*) de programmes l'émergence d'un léviathan numérique à même de remplacer toute autre forme de gouvernance et de souveraineté : « Un certain humanisme \[\...\] croit encore se tenir au centre du jeu. Nous devons abandonner l'exigence selon laquelle toute intelligence artificielle arrivant à la sensibilité ou à la sapience doit se soucier profondément de l'humanité. » (Bratton, 2014). Il s'agit de savoir si, sous couvert d'efficacité, le design doit se lier à une conduite technique qui travaille contre nous en faisant de l'inintelligible un prérequis à l'optimisation.

• (select:18)Le *deep learning* (et le *machine learning*) se présente la plupart du temps sous une allure dématérialisée, faisant fi du lourd écosystème tant technique (*data centers*, extraction de métaux rares, etc.) qu'humain nécessaire à son fonctionnement.(deselect:) Derrière les robots, le *deep learning* ne peut pas fonctionner sans ceux que le sociologue Antonio Casilli appelle « les travailleur·euses du clic » (Casilli, 2019), à savoir des prolétaires du Sud global chargé·es de trier les données collectées.

• De par leur efficacité, les réseaux de neurones se présentent comme la seule modalité possible de l'IA. Or la confusion de l'intelligence avec les sciences statistiques et la pseudo-autonomie de ces technologies doivent être questionnées (Moulier-Boutang et Kyrou, 2018, p. 7-15). Il est en effet notable que l'intelligence artificielle ne vise qu'à simuler une compréhension restreinte de l'intelligence humaine qui ne fasse et ne puisse que fonctionner (comme dans les champs du *nudge*, du *neuromarketing*, etc.). Les IA contemporaines participent de l'idéal d'un fonctionnement « continu » du psychisme humain et minorent d'autres approches, comme la psychanalyse, qui au contraire se basent sur la notion de dysfonctionnement.

<a name="assister-ou-asservir"></a>
#### [↑](#essay) Assister ou asservir

(select:8)Ce risque d'assujettissement de l'être humain --- son assignation à de la pure utilité --- nous emmène au plus près des enjeux croisés du design et des intelligences simulées.(deselect:) Comme le note le chercheur Emanuele Arielli, « la rencontre entre l'IA et l'esthétique est cruciale parce que l'esthétique est considérée comme un domaine fondamentalement humain » (Arielli, 2021, chap. 1). Le *deep learning* appliqué aux métiers de la création s'inscrit dans la longue histoire de leur informatisation, une rencontre qui n'a rien d'évident. Dans un article revenant sur les modes de dessin à l'ordinateur à partir des années 1960, l'historien de l'architecture Jordan Kauffman montre ainsi que la transposition de la logique formelle dans le champ du design pose de nombreux défis techniques mais aussi, et surtout, épistémologiques :

« Rétrospectivement, c'est vis-à-vis de la création elle-même que le passage à l'informatique semble avoir été le plus compliqué. Parce que le processus créatif n'est pas aisément décomposable en règles systématiques, scientifiques ou mathématiques pouvant générer des réponses exactes, parce que pour designers et architectes, l'expression d'une idée à travers le dessin est le mode principal de création et de communication, il a fallu à l'époque s'efforcer de concilier ordinateurs et pratiques du dessin \[\...\] : comment, au stade précoce de la conception assistée par ordinateur, la machine \[a-t-elle\] affecté et assimilé l'acte de dessiner, le processus de dessin et de création, et les dessins eux-mêmes \[?\] » (Kauffman, 2016)

Alors que des propositions diverses et ouvertes balisent les débuts des ordinateurs personnels avec des débats sur le rôle et la place des programmes dans les champs de la création, l'informatique dominante va s'engouffrer dans une voie à sens unique où priment l'automatisation et le rendement : interfaces graphiques utilisateurs (GUI) et annexion du design par l'UX Design (années 1970), logiciels de conception et de publication assistés par ordinateur (CAO et PAO, années 1980), hégémonie des médias sociaux (années 2000), *templates*, *guidelines* (gabarits visuels) des *app stores* (fin des années 2000), mise en ligne de banques d'images et de portfolios (Deviant Art, 2000, Flickr, 2004, Behance, 2005), logiciels de prototypage Web (années 2010) et intégration du *machine learning* dans des boutons de logiciels (Adobe Sensei, 2016 ; Runway ML, 2019). Ces principaux développements <a name="fig-4">[\[Fig. 4\]](#ref-fig-4)</a> dessinent une trajectoire où le design s'automatise et perd de son sens historique, puisque passent au second plan l'inventivité, la capacité à interroger un contexte, le contact avec les matériaux, et de façon plus générale le cheminement à travers les formes et les usages (Masure, 2023a). En adhérant sans recul aux principes de rentabilité, d'efficacité et de fluidité, une bonne part du design se sera écartée des conditions historiques de son apparition, à savoir marquer un écart avec les *ersatz* des révolutions industrielles (Masure, 2023b). Le problème qui se pose alors, en termes contemporains, est l'installation d'une confusion entre les designers assisté·es par l'ordinateur et l'ordinateur assisté par les designers. S'étant automatisé·es, ils·elles courent le risque que la machine soit plus performante, comme l'entrevoyait, grinçant, l'artiste et designer John Maeda :

« Il est difficile de distinguer le designer assisté par ordinateur de l'ordinateur assisté par un designer. \[...\] Les designers ne définissent plus la culture ; ils doivent se conformer à une culture définie par les évangélistes des technologies. Dans son essai *Digital Design Media* (1991), le professeur d'architecture William Mitchell formule la conclusion logique de cette situation difficile : "Nous sommes très proches du point où le designer moyen n'a plus rien à vendre qui vaille la peine d'être acheté". » (Maeda, 1995)

(image: illustrations/Fig4.png caption: Fig.4 - Runway)

Avec l'explosion de la quantité des données disponibles en ligne et avec la mesure en temps réel des comportements (*tracking*), le modèle de la quantification de toute activité (*data science*) va s'intégrer dans l'ensemble des champs du design (design graphique, design de mode, design produit, architecture, etc.) : la culture, au sens large, se voit alimentée par la production automatisée d'artefacts culturels. Les technologies du *deep learning* des années 2010 vont renforcer ce contexte où la machine n'est plus comprise comme une collaboratrice (un appareil) ou une assistante (un outil), mais comme un moyen efficace (un dispositif) de remplacer le facteur humain pour viser davantage de rentabilité.

<a name="stereotyper-les-methodes-de-conception"></a>
#### [↑](#essay) Stéréotyper les méthodes de conception

(select:12)Avec les IA du *deep learning*, l'autorité de l'auteur·trice et sa signature visuelle sont mises en tension par des programmes capables d'analyser et de synthétiser (d'imiter) de façon automatique de larges jeux de données.(deselect:) Comme évoqué en introduction de cet essai, des systèmes dits « intelligents », comme GPT-3 (2020), DALL·E (2021), Disco Diffusion (2021) ou Midjourney (2022), poussent à un autre seuil la logique de fluidification des filtres et des menus propres aux logiciels de PAO, puisqu'une simple commande textuelle (un *prompt*) suffit à générer un ensemble d'images en remixant des données préalablement collectées et vectorisées. La structure des *prompts*, qui fait l'objet de nombreux débats, varie selon les systèmes et leur évolution, et associe généralement des thématiques et des styles et expressions rappelant les filtres et moteurs de rendu --- par exemple : « *cozy cyberpunk futuristic room in a city during daytime with a window overlooking the skyline, ultra photoreal, photographic, concept art, 4K, octane render, cinematic lighting, highly detailed* » (nous conservons ici la formulation en anglais, celle-ci étant plus efficiente). Pour apprivoiser ces systèmes, explique le designer graphique Étienne Mineur (<a class="interview" style="cursor:pointer" onclick="openWindow('Étienne Mineur', 'interviews/Etienne-Mineur', event)">Mathieu</a>, 2022), il faut assimiler la structure de ces langages et savoir mettre les mots dans le « bon sens » (c'est-à-dire aligner son langage depuis celui de la machine), parfois en les pondérant avec des signes de ponctuation.

(image: illustrations/Fig5.png caption: Fig.5)

De façon générale, avec le *deep learning*, la machine devient capable d'associer un lexique à des formes, qu'elles soient *bitmap* (à base de pixels) <a name="fig-5">[\[Fig. 5\]](#ref-fig-5)</a>, vectorielles ou tridimensionnelles (Apple GAUDI, 2022) <a name="fig-6">[\[Fig. 6\]](#ref-fig-6)</a>. Cette promesse d'une création (presque) sans intervention humaine explicite relance le vieux débat consistant à savoir si une machine peut se substituer à un·e designer --- une formulation binaire qui selon nous fait obstacle à la compréhension du large spectre des implications du *machine learning*. Dans un article au titre sans équivoque (« If You're Worried About DALL·E Replacing Illustrators, You Don't Understand The Power of Illustration ») (Posture, 2022), l'illustrateur Julien Posture montre que les IA contemporaines ne remplacent pas les illustrateur·trices mais une idée préconçue de l'illustration, à savoir l'exécution servile d'un *brief* textuel par le recours à tel ou tel style visuel à la mode --- ce que proposaient déjà des plateformes de microtravail comme Fiverr (2010) ou Upwork (2015), où des personnes à l'autre bout du monde peuvent réaliser un logo pour 5 dollars. Ce type d'approche se limite *in fine* à accélérer les réponses à des commandes clairement formulées. Cela ne va toutefois pas de soi pour beaucoup de clients, dont la compréhension des besoins nécessite un temps d'échange conséquent qui dépasse le strict cadre du *brief* (reste à savoir combien auront conscience de cette difficulté et ne choisiront pas la facilité du choix sur catalogue) : « générer n'est pas nécessairement œuvrer » (Ertzscheid, 2022).

(image: illustrations/Fig6.png caption: Fig.6 - Apple GAUDI)

Une des façons de comprendre ces dynamiques de formatage réside dans l'étude de la constitution des bases de données, qui ne sont pas toutes ouvertes, et qui orientent fortement les résultats. Beaucoup de ces systèmes contiennent une liste de mots-clés interdits pour prémunir les développeurs de toute mésaventure --- une censure sournoise qui peut toutefois être contournée par le recours à des synonymes. Notons aussi que des designers comme Philippe Starck n'apparaissent pas dans DALL·E, ce qui pose d'importants défis juridiques (Benhamou, 2022) en matière de respect des droits d'auteurs et de commercialisation des productions (certains systèmes de *prompts* n'autorisent pas la revente des images générées, tandis que d'autres, comme Stable Diffusion, les placent sous licence libre CC 0).

Plus fondamentalement, ces programmes à base de *prompts* peuvent faire écho à l'art conceptuel des années 1960 (où l'œuvre d'art se tient dans l'intention verbale et non pas dans sa matérialité) ou encore à la Genèse biblique (où le mot doit précéder la chose). Or, selon le designer et chercheur Martin Tricaud, la verbalisation d'une intention créative n'a rien d'évident :

« Poser des mots sur ce que l'on fait est beaucoup plus compliqué que ce que les concepteur·trices de systèmes comme DALL·E peu-vent imaginer. De plus, comme le montre la sociologue Eva Illouz, formaliser verbalement ses intentions peut entraîner une paralysie décisionnelle et une apathie émotionnelle. Par exemple, dans les applications de rencontres, les personnes sont invitées à mettre des mots de plus en plus précis pour définir ce qu'elles cherchent, ce qui dissipe la magie. Si je dessine ou que je peins des tableaux abstraits, c'est précisément car je ne suis pas en capacité de raisonner verbalement. Dans l'art et dans le design, il y a des règles non verbales de composition et de construction, et l'on n'est pas sans cesse dans l'anticipation d'intentions et dans la matérialisation d'un langage. » (<a class="interview" style="cursor:pointer" onclick="openWindow('Martin Tricaud', 'interviews/Martin-Tricaud', event)">Mathieu</a>, 2022)

(select:17)Dans la logique des *prompts*, ce qui compte n'est plus le temps (le labeur) nécessaire à la réalisation (ce dernier étant confié à des machines), mais la recette magique permettant d'obtenir le résultat, comme le montre les exemples d'une startup faisant payer le texte précédant la génération d'une série d'images produites par DALL·E 2(deselect:) (Wiggers, 2022) ou le développement de programmes dédiés (Shane McGeehan, Prompter, 2022) <a name="fig-7">[\[Fig. 7\]](#ref-fig-7)</a> --- faisant courir le risque de basculer dans « un capitalisme sémiotique total » (Ertzscheid, 2022). Sur le plan économique, le *deep learning* pourrait modifier la chaîne de valeur du design en réduisant le coût de l'exécution (diminution de la valeur perçue), et en augmentant celui du conseil (difficilement modélisable et donc automatisable). On pourrait même arriver à une partition entre d'un côté un design « d'élite » avec des commandes à forte valeur ajoutée où une grande part de liberté et d'originalité est attendue (comme dans le cas du secteur culturel), et de l'autre côté un design « moyen » où des IA prennent en charge des commandes stéréotypées, avec un risque de déclassement des designers occupant ce segment. Pour éviter ce risque, le designer Boyd Rotgans note que « faire quelque chose de nouveau avec l'apprentissage automatique et ne pas refaire le même tour demande beaucoup de connaissances techniques, ce qui est un grand défi pour les designers graphiques. » (<a class="interview" style="cursor:pointer" onclick="openWindow('Boyd Rotgans', 'interviews/Boyd-Rotgans', event)">Mathieu</a>, 2022)

(image: illustrations/Fig7.png caption: Fig.7 - Prompter)

<a name="imiter-et-uniformiser"></a>
#### [↑](#essay) Imiter et uniformiser

Ce qu'automatisent les technologies du *deep learning*, dans le cas des *prompts*, n'est donc pas le design au sens fort du terme (interroger un contexte, reformuler une demande), mais sa réduction à la génération d'artefacts visuels ressemblant à ce qui a déjà existé. Plus précisément, il s'agit d'une vision schématique et biaisée du passé, puisque les données servant de base aux résultats sont celles qui sont bien représentées en ligne (Crawford et Paglen, 2019) --- ce qui laisse de côté beaucoup d'époques et de contextes culturels. Il est frappant de constater que cette tendance à automatiser la production de produits culturels (œuvres d'art, etc.), sous couvert d'innovation, va de pair avec le retour du vieux concept d'imitation. Les deux exemples artistiques mentionnés en introduction (*The Next Rembrandt*, *2016 ; Portrait d'Edmond Belamy*, 2018), qui utilisent des techniques de pointe et dont les médias louent le caractère de nouveauté, peuvent, paradoxalement, être replacés dans la logique de l'Académisme du milieu du XIX^e^ siècle en raison de leur volonté d'imiter des œuvres canoniques de l'histoire de l'art. On peut aussi penser, encore plus loin, à la tradition des moines copistes, où l'exercice de la répétition prend valeur de viatique pédagogique à partir duquel un langage artistique peut surgir.

Ces rapides ancrages historiques montrent que les technologies du *deep learning*, contrairement à ce que peuvent laisser croire les fantasmes de rupture et d'agentivité les entourant, sont moins concernées par le développement d'une facture singulière que par la reproduction efficace du passé. Cette tendance fait écho à « l'effet diligence » du chercheur Jacques Perriault selon qui il est fréquent que des « protocoles anciens \[soient\] appliqués aux techniques nouvelles » (Perriault, 2000). Le cas de l'invention de la photographie peut aussi aider à éclairer la situation contemporaine. Lorsqu'elle apparaît à la fin du XIX^e^ siècle, celle-ci va tout d'abord imiter les codes de la peinture et devenir une façon plus rapide de produire des images ; or la photographie comme art n'émerge qu'à condition d'un écart avec le modèle pictural (Huyghe, 1999). Dès lors, selon nous, la question de l'acceptation d'un monde façonné par les IA se pose moins en terme de remplacement (de l'humain par la machine) qu'en terme de recouvrement : un environnement dans lequel on ne pourrait pas distinguer ce qui est produit, ou non, avec ces intelligences simulées. Il est seulement possible d'automatiser ce qui a été simplifié en amont, ce qui rejoint l'intuition d'Alan Turing quand il dit que « dès qu'une technique devient un tant soit peu stéréotypée, il devient possible de concevoir un système de tables d'instructions qui rend capable le calculateur électronique de l'exécuter tout seul » (Turing, 1947, p. 392). Cette volonté de mécaniser toute action au nom du rendement, derrière les atours séduisants de la magie, selon le philosophe Pierre-Damien Huyghe, a pour revers de ne produire que de l'uniformité :

« Dans le monde de la mécanisation, qu'il s'agisse de travailler ou de seulement consommer, l'uniformisation du temps est une affaire. Ce monde est dans la constance des cadences, de l'égal, du répétitif. Ce qu'il produit d'une manière inédite, c'est l'uniformité. Ainsi l'abondance de la société industrialisée est-elle en profondeur, et même si elle s'en défend, hantée par le risque de la monotonie. » (Huyghe, 2013)

Pour tracer des chemins de traverse plus soutenables que la tendance à l'uniformisation de l'innovation, il faut donc dépasser l'opposition humain/machine, et plus précisément l'idée d'un « remplacement » des designers par des programmes supposément intelligents. Posée sous forme binaire, comme le montre Kate Crawford, cette question conduit à une impasse :

« Nous retrouvons constamment l'idéologie du dualisme cartésien : le fantasme selon lequel les systèmes d'IA sont des cerveaux désincarnés qui absorbent et produisent du savoir indépendamment de leurs créateurs, de leurs infrastructures et du monde plus généralement. Ces illusions nous détournent de questions bien plus pertinentes. Qui ces systèmes servent-ils ? Quelle est l'économie politique de leur construction ? Et quelles en sont les conséquences planétaires ? » (Crawford, \[2021\] 2022)

Derrière le caractère magique de l'idée générale d'« intelligence artificielle » (le fantasme de la mécanisation d'un psychisme normatif), le fonctionnement du *deep learning* réduit l'apprentissage au dressage, c'est-à-dire à l'intériorisation de comportements et à l'imitation de modèles. La logique de la mécanisation, appliquée à l'informatique, revient à figer la langue, puisqu'une formalisation préalable est nécessaire pour pouvoir la soumettre à un calcul (c'est pour cela qu'on parle de « langages formels »). Comme le rappelle le philosophe Jean Lassègue, la langue n'est pas stabilisée une fois pour toute, mais doit être comprise comme une matière sans cesse retravaillée de l'intérieur par les pratiques et par la littérature :

« La façon dont la langue métaphorise son matériau est telle qu'une approche "dictionnairique" du lexique ne sera jamais suffisante pour rendre compte de l'intelligibilité de la langue, parce que la transformation de son mode de production est son moteur même. Quand vous utilisez des mots, vous faites en même temps quelque chose aux mots que vous utilisez et vous transformez le sens du mot en question. » (Lassègue, 2018)

Avec les *prompts* du *deep learning*, le travail du langage est court-circuité par le passage sans effort du verbe à l'image --- à la nuance près que savoir parler le langage de la machine est déjà un travail. Le remplacement de l'esthétique (la science du sensible) par le registre verbal engendre le risque de rester dans la littéralité (dans la monstration totale) et non pas dans la transformation du sens (dans l'interprétation voire dans la subversion). Une illustration, par exemple, n'est pas la mise en image servile d'un texte mais un jeu visuel faisant appel à des non-dits et ellipses que le·la lecteur·trice doit combler.

<a name="confondre-creation-et-production"></a>
#### [↑](#essay) Confondre création et production

L'usage et la médiatisation de DALL·E s'appuient sur la séduction d'un sentiment s'apparentant à de la magie, à savoir un résultat dont il est difficile d'expliquer le fonctionnement et dont les éléments sont agencés pour faire diversion et éviter de se poser des questions. Le délai d'exécution des systèmes de *prompts*, s'il est plus rapide qu'un labeur humain, n'est pas pour autant immédiat. Tout comme un appareil photographique « travaille » seul pendant une fraction de temps, le délai de calcul nécessaire à la génération des images ouvre paradoxalement un espace de rêverie pendant lequel on se demande ce que la machine va faire. Actuellement de quelques minutes, cette durée peut cependant être réduite en payant les systèmes qui le permettent --- l'idéal visé étant celui de l'immédiateté.

(select:19)Pour mieux comprendre les fondements du fantasme de la mise au monde d'une idée débarrassée des vicissitudes matérielles (des aléas de l'exécution), il est instructif de remonter à l'apparition des appareils d'enregistrement au XIX^e^ siècle. Voyant dans la photographie alors naissante de quoi concurrencer les arts installés comme la peinture, le poète Charles Baudelaire dénonce avec virulence la prétention de la mécanique à faire art(deselect:) :

« Dans ces jours déplorables, une industrie nouvelle se produisit, qui ne contribua pas peu à \[\...\] ruiner ce qui pouvait rester de divin dans l'esprit français. Cette foule idolâtre postulait un idéal digne d'elle \[\...\] : "\[\...\] Je crois que l'art est et ne peut être que la reproduction exacte de la nature \[\...\]. Ainsi l'industrie qui nous donnerait un résultat identique à la nature serait l'art absolu." \[\...\] Puisque la photographie nous donne toutes les garanties désirables d'exactitude (ils croient cela, les insensés), l'art, c'est la photographie." À partir de ce moment, la société immonde se rua, comme un seul Narcisse, pour contempler sa triviale image sur le métal. Une folie, un fanatisme extraordinaire s'empara de tous ces nouveaux adorateurs du soleil. » (Baudelaire, \[1859\] 1999)

Commentant ce texte, le philosophe Pierre-Damien Huyghe fait l'hypothèse que Charles Baudelaire rejette la photographie comme art car celle-ci introduit auprès du plus grand nombre « un insensé désir d'exactitude » (Huyghe, 2022, p. 71-72), là où Walter Benjamin y voit au contraire la possibilité de fonder une nouvelle culture où le procédé de reproduction ne serait pas masqué mais avéré (la reproduction exacte n'existant pas). Ces vieux concepts de mécanique et d'exactitude ne sont donc pas derrière nous, puisqu'ils nourrissent les fantasmes entourant les IA et qui promettent une reproduction exacte et sans efforts non pas de la nature mais du passé. Afin de mieux comprendre ces enjeux, il importe de distinguer entre les notions de « création » (la vision romantique d'une mise au monde *ex nihilo*) et de « production » (l'attention portée aux modalités techniques et rapports sociaux). On peut d'abord noter que le concept de création est historiquement récent dans le champ de l'art :

« Au moment où l'Ancien régime se défait, où se déploie la révolution industrielle, les artistes revendiquent \[\...\] le terme de "création" --- une notion \[\...\] issue du dogme biblique de la genèse --- pour signifier leur souveraine sensibilité, leur libre vouloir et établir l'art comme champ autonome parmi les activités humaines. » (Menghini, 2021)

À cette tradition s'oppose, plus proche de nous, la pensée « matérialiste » développée par des philosophes comme Karl Marx ou Walter Benjamin, pour qui il importe d'examiner les médiations permettant à l'art (et par extension au design) d'exister pour mieux saisir son potentiel émancipatoire. Dans son essai *L'artiste comme producteur*, Walter Benjamin cherche ainsi à savoir non seulement « quelle est la position d'une œuvre littéraire *à l'égard* des rapports de production de l'époque \[mais, avant tout,\] quelle est sa place *dans* ces mêmes rapports » (Benjamin, \[1934\] 1969). Il s'agit, pour Benjamin, d'« indiquer la différence essentielle qui existe entre le simple approvisionnement d'un appareil de production et sa transformation » (Benjamin, \[1934\] 1969, p. 110). De tels propos sont précieux pour mettre en exergue les limites des technologies du *deep learning* dont la séduction tient à leur occultation de toute contingence matérielle. Pour reprendre les termes de Walter Benjamin, ces programmes ne peuvent qu'approvisionner l'appareil de production sans jamais chercher à le transformer. Autrement dit, elles sont « réactionnaires » et non pas « révolutionnaires ». Par exemple, si une IA peut « reproduire » (créer) un tableau à la façon de Rembrandt --- sans efforts apparents, et sans que la technique ne soit vraiment une question ---, elle aura beaucoup plus de difficultés à « produire » non pas seulement un paradigme pictorial aussi fort que Rembrandt, mais aussi de nouvelles formes d'expression dépassant les catégories habituelles (peinture à l'huile, musique électronique, interface de site Web, etc.). Se demander « si les intelligences artificielles peuvent créer » est mal poser le problème, d'une part car ces dernières n'ont rien de magique, et d'autre part car le vocabulaire de la création, dégagé des contingences matérielles, engendre une incapacité à envisager la technique comme un lieu d'exploration et donc de « production ». Interrogeant une IA (GPT--3) pour savoir de quelles manières le métier d'illustrateur·trice va évoluer par rapport à l'arrivée de l'intelligence artificielle, le designer Étienne Mineur s'est vu proposer une réponse étrangement plus lucide que bien des discours technophiles : « Pour survivre dans un tel environnement, l'illustrateur·trice devra renoncer à sa révérence presque superstitieuse envers la créativité[^7]. » L'enjeu est donc de faire en sorte que les technologies du *deep learning* puissent produire et pas seulement reproduire, ce qui fait écho aux propos de l'artiste et designer László Moholy-Nagy dans son article « Production --- Reproduction » (1922) :

« La production (la création humaine) servant au premier chef la constitution humaine, nous devons tenter d'exploiter à des fins productives les appareils (moyens) qui jusqu'alors n'avaient été utilisés qu'à des fins reproductives. Cela nécessite un examen approfondi, basé sur les questions suivantes :

--- À quoi sert cet appareil (ce moyen) ?

--- Quelle est l'essence de sa fonction ?

--- Sommes-nous capables, et est-ce pertinent d'en élargir les possibilités de sorte qu'il puisse également servir à la production ? » (Moholy-Nagy, \[1922\] 2007, p. 136)

Au vu de tels propos, on peut désormais poser que l'enjeu, pour le design, ne consiste pas à viser une automatisation totale de la création puisque celle-ci, scriptée, ne conserve de l'idée romantique d'une libre volonté divine que l'immédiateté du résultat. L'écart avec une vision mimétique (reproductive) nécessite au contraire d'engager un travail « avec » le monde artificiel des réseaux de neurones --- ce qui implique de redéfinir ce que l'on entend sous les notions de création et de design. En effet, si l'on soutient sous le nom de design un champ de pratiques contestant l'assignation des techniques à des principes de rentabilité, ce dernier peut faire office de contre-pouvoir aux ambitions les plus avilissantes et révéler des marges de manœuvre et de nouvelles opportunités, y compris dans le cas de techniques *a priori* peu ouvertes à l'exploration, comme le *deep learning*. Les différents axes de travail que nous proposons ci-après ont pour point commun de contester l'idée d'une primauté ou d'une exclusivité de la création humaine, qui n'existe que située dans des milieux techniques et qui, dès lors, est forcément hybridée ou plutôt « appareillée ». Analysant ces enjeux dans le champ de la création, les chercheurs Lev Manovich et Emanuele Arielli se demandent ainsi :

« Si l'attribution de l'intelligence \[à une machine\] est une ligne d'horizon qui ne peut jamais être atteinte, on peut se demander s'il existe des compétences humaines au-delà de cette ligne : chaque fois que les machines "résolvent" une compétence humaine spécifique, cette compétence cesse d'être une véritable intelligence, se révélant plus mécanique qu'il n'y paraît. Cela peut avoir des conséquences sur notre compréhension de l'intelligence humaine elle-même. » (Manovich et Arielli, 2021, chap. 3)

De même que la notion de machine a (re)défini les spécificités du corps humain (comme par exemple avec l'histoire de la dissection où la dépouille humaine devient du matériel anatomique, et donc de connaissance) (Saint-Jevin, 2019, p. 373), l'informatique va agir comme un « miroir automate » (Chazal, 1998) de l'esprit en rivalisant avec certaines de ses tâches, ce qui va obliger à penser non seulement ce qui fonde sa singularité, mais aussi ce qu'il emporte de mécanique. Ce dépassement de l'opposition humain/machine va permettre d'envisager d'autres rapports au *machine learning* que celui de son instrumentalisation à des fins productives.

<a name="potentialités-créatives"></a>
### [↑](#essay) Potentialités créatives

<a name="reveler-les-dynamiques-de-standardisation"></a>
#### Révéler les dynamiques de standardisation

(select:7)Le premier axe d'opportunité que nous proposons d'explorer consiste à mobiliser les technologies du *deep learning* pour révéler des dynamiques de standardisation au sein de productions existantes.(deselect:) Même si chaque générateur visuel (DALL·E, Stable Diffusion, etc.) possède son « identité graphique presque immédiatement reconnaissable » (Ertzscheid, 2022), ces derniers ne produisent bien souvent qu'une image « moyenne » (résultant de données existantes) et qui peut être envisagée comme un guide de ce qu'il ne faut pas (re)faire. Il faut garder en tête que la notion d'imitation traverse déjà largement le design et la *pop culture*. Ainsi, la sortie en 2020 par l'entreprise Kioxia d'un manga « conçu par une IA » à la façon d'Osamu Tezuka est moins l'indice d'un remplacement des dessinateur·trices de bandes dessinées par ces programmes que la mise en évidence de motifs artistiques et stylistiques intrinsèques à l'œuvre du mangaka. De nombreuses productions pop culturelles témoignent de cette tendance à la répétition, telles que les longs-métrages de Walt Disney où des boucles d'animation rejouent des variations d'anciens films avec d'autres personnages. Dans le champ de la mode, similairement à l'exemple de Tezuka, le jeu de données structurées « Fashion MNIST » (2018) <a name="fig-8">[\[Fig. 8\]](#ref-fig-8)</a> propose 60 000 *sprites* (éléments visuels) issus du catalogue de la marque de vêtements Zalando à partir desquels trier d'autres images, ou générer d'autres vêtements.

(image: illustrations/Fig8.png caption: Fig.8 - MNIST)

Alors que ces exemples sont profilés dans une optique de rendement (ou de démonstration technique), on pourrait au contraire mobiliser les IA connexionnistes pour étudier le passé et le présent à la façon dont la Digital Art History renouvelle l'histoire de l'art par le recours aux méthodes informatiques. Il est possible de lire sous cet angle le projet *Balenciaga AI* (2018) de l'artiste Robbie Barrat, qu'il décrit en ces termes :

« À partir d'un corpus de défilés, de catalogues et de campagnes de Balenciaga, un réseau \[de neurones\] a été entraîné à reconstruire des tenues Balenciaga à partir de silhouettes \[\...\]. Il en résulte de nouvelles tenues, mais fortement inspirées des dernières années de Balenciaga \[\...\]. Le réseau \[\...\] produit des tenues étranges qui ignorent complètement \[les\] fonctions \[usuelles des vêtements\]. » (Barrat, 2018)

Cette nouvelle collection de vêtements révèle en creux, sous forme absurde et troublante, le caractère répétitif de l'existant, et se révèle même par endroits plus radicale que son point de départ. La distance avec l'esthétique photoréaliste, encore difficilement accessible par les IA et ici mise de côté volontairement, produit des silhouettes qui abolissent les catégories vestimentaires habituelles : sac, veste, pantalon, etc., et qui laissent place à l'imagination. L'exemple de *Balenciaga AI* nous invite à explorer ce que pourraient être des zones grises du *machine* *learning*. Il s'agirait ici d'actualiser des intuitions comme celles de l'artiste Hito Steyerl qui, dans un texte intitulé « En défense de l'image pauvre », invite à considérer positivement leur condition contemporaine dégradée (pixelisée, etc.) résultant de pratiques d'*editing*, de *sampling* et de *remix* :

« L'image pauvre ne concerne plus la chose réelle --- l'original originaire. Il s'agit plutôt de ses propres conditions réelles d'existence : la circulation en essaim, la dispersion numérique, les temporalités fracturées et flexibles. Il s'agit de défiance et d'appropriation, tout comme de conformisme et d'exploitation. » (Steyerl, 2009)

Pour orienter les IA du *deep learning* dans une optique de production, une autre attitude consisterait à mobiliser leurs capa-cités d'analyse visuelle pour établir des généalogies insoupçonnées entre des objets, comme le fait le projet *X Degrees of Separation* <a name="fig-9">[\[Fig. 9\]](#ref-fig-9)</a> de l'artiste Mario Klingemann (Google Arts & Culture Lab, 2016). Cette interface en ligne trace une généalogie fictive entre deux artefacts artistiques préalablement choisis en sélectionnant des œuvres « intermédiaires » triées par périodes et présentant des similitudes formelles (la définition des étapes est opérée par de l'apprentissage automatique appliqué à des archives en ligne de musées). Cette chaîne de ressemblances provoque des rapprochements inattendus entre des œuvres de provenances hétéroclites, qui se heurtent toutefois à d'autres cultures que celles de l'Occident et pour lesquelles ces associations formelles ne fonctionnent pas forcément : ce ne sera pas le moindre des défis des IA que d'éviter de produire des formes d'ethnocentrisme algorithmique (Audry, 2019).

(image: illustrations/Fig9.png caption: Fig.9 - X Degrees of Separation)

Sur ce principe d'une sérendipité ouverte et paramétrable, on pourrait inventer des systèmes d'aide à la décision pour artistes et designers permettant de comparer des intentions de projets à des jeux de données structurées : coefficients de ressemblance, de dissemblance, propositions de changements, variations, etc. Inspirée des *Cultural Analytics* (Manovich, 2020), cette voie permettrait de prendre de la distance avec l'injonction à l'originalité totale, qui suppose que les artistes et designers ont soit « tout » soit « rien » à dire (qu'il n'y a pas d'entre-deux), alors que l'histoire de ces champs montre que bien des œuvres admirées aujourd'hui sont des emprunts, copies ou interprétations de leur époque ou du passé.

<a name="responsabiliser-l-injonction-a-la-simplicite"></a>
#### [↑](#essay) Responsabiliser l'injonction à la simplicité

(select:10)Le deuxième axe de potentialité créative du *machine learning* consiste à contrecarrer l'illusion de l'automatisation.(deselect:) Il s'agit tout d'abord de déjouer la prétention de ces technologies numériques à « résoudre » plus de problèmes qu'elles n'en engendrent. Derrière la simplicité se cache un manque de cohérence et d'intelligibilité, lequel peut être révélé par des démarches de création. Dans une installation intitulée *Of Machines Learning to See Lemon* (2018) <a name="fig-10">[\[Fig. 10\]](#ref-fig-10)</a>, les artistes Alistair McClymont et John Fass disposent des objets colorés sur une vaste étagère en carton aux rangements cubiques. Sans que nous parvenions à en dégager des règles, un semblant de logique semble émerger de cette classification. Reprenant du registre artistique des natures mortes la logique coloniale et capitaliste des fruits représentés, cette œuvre manifeste la difficulté des algorithmes d'apprentissage automatique à identifier des objets (lorsque ces derniers sont regroupés, éclairés ou orientés différemment) et à expliciter la façon dont le résultat (l'étiquetage) est opéré. Les programmes de reconnaissance de formes, comme le notent les auteurs, restent « mystérieux dans leur origine, sujets à l'erreur, ambigus dans leurs valeurs, d'une fiabilité erratique et d'une authenticité douteuse » (McClymont et Fass, 2018). Plus encore, ajoutent-ils :

« Ce processus de classification invisible est généralement destiné à produire des décisions automatisées qui peuvent avoir des conséquences profondes sur la liberté individuelle et collective. Les avantages possibles de l'apprentissage automatique sont nombreux, mais nous courons le risque de développer des technologies d'une complexité telle que nos capacités à les façonner pour servir le bien commun sont sévèrement limitées. Avec cette installation, nous espérons ouvrir l'apprentissage automatique à l'exploration créative et à la critique. » (McClymont et Fass, 2018)

(image: illustrations/Fig10.png caption: Fig.10 - Of Machines Learning to See Lemon)

Deux autres exemples montrent que l'écosystème technique des intelligences artificielles n'est en rien « immatériel ». *Anatomy of an AI System* (2018), une grande cartographie critique réalisée par les chercheur·euses et designers Kate Crawford et Vladan Joler analyse visuellement l'ampleur de l'infrastructure humaine et non humaine permettant à une enceinte à commande vocale (*text-to-speech*) Amazon Echo de fonctionner. Ainsi disséquées, ces couches et sous-couches disposées pour ne pas être vues dissipent les fantasmes d'usages « fluides » et « sans frictions » promus par l'industrie des services, car la promesse de simplicité côté usager·ères engendre une grande complexité en amont où « chaque petit moment de confort --- qu'il s'agisse de répondre à une question, d'allumer une lumière ou de jouer une chanson  --- nécessite un vaste réseau planétaire, alimenté par l'extraction de matières premières non renouvelables, de main-d'œuvre et de données » (Crawford et Joler, 2018). Un autre exemple éclairant la dimension matérielle des technologies numérique est l'exposition *Praying for my Haters* (Centre Culturel Suisse, Paris, 2019), dans laquelle l'artiste Lauren Huret documente le travail invisible des modérateur·trices des médias sociaux, dont le tri, structurellement, ne peut pas être entièrement automatisé. Des témoignages vidéo éclairent ces conditions de travail mortifères où l'effacement du sens moral, nécessaire à l'exécution de telles tâches, substitue le registre comportemental à l'intelligence.

De ces deux cas, il est paradoxal de constater que la simulation de l'intelligence humaine implique d'ôter à des humains ce qui les fait exister au-delà du biologique --- ce qui résonne avec les propos du « proto-designer » William Morris au tournant des révolutions industrielles selon qui il importe de « montrer à quel point l'ouvrier est éloigné d'avoir une part quelconque, si petite qu'elle soit, dans l'art, quand il est au travail ; \[\...\] car ceux-là mêmes qui sont occupés à fabriquer \[\...\] des "objets d'art" doivent travailler toujours comme des machines ou comme des esclaves des machines » (Morris, \[1884\] 1904). Mais, contrairement à William Morris qui voyait dans la lutte des classes la seule façon d'abolir la domination des machines sur l'humain, l'idée moderne du design aura montré que plusieurs rapports à une même technique sont possibles, et ce même si son économie la pousse dans une direction dominante : un travail « avec » (et non pas sous ou contre) les machines peut bousculer la prégnance du rendement sur l'esthétique et dépasser la dialectique du maître et l'esclave.

Il en suit que nous proposons d'appeler « design sous artifice » la couverture d'opérations techniques à des fins économiques et politiques dont participent les intelligences artificielles dominantes. Ôter ce vernis reviendrait à prendre en compte, dans des démarches de design, les conditions matérielles et le labeur humain nécessaires aux productions et à leur fonctionnement. On s'éloignerait ainsi de la vision démiurgique d'une création numérique *ex nihilo*, finalement assez masculine dans ses connotations implicites (la recherche de performance, le commandement, l'effacement du contexte), au profit d'un travail valorisant les vulnérabilités et l'attention aux autres. Il s'agit ici, en filigrane, d'opérer une déconstruction d'une certaine idée de l'homme, du mâle, qui ne montrerait jamais son intériorité, ses entrailles ou ses faiblesses. Sortir de cette logique du recouvrement reviendrait alors à accueillir positivement le manque, la défaillance, l'ambiguïté et l'incertitude. Dans le champ du *machine learning*, révéler les strates techniques sous-jacentes ne va pas sans difficultés, car la barrière technique est de plus en plus haute et se prête mal aux détournements. Selon le développeur et artiste Nicolas Barradeau, il importe de s'intéresser à la « matière » du *machine learning*, à savoir le choix de tel ou tel modèle statistique :

« Pour des artistes comme Mario Klingemann ou Memo Akten, il n'est pas suffisant d'ouvrir des programmes comme Runway ML et de chercher à épuiser le modèle qu'ils embarquent. Ce qui les intéresse est de descendre dans les couches et de comprendre comment fonctionne un modèle optimisé, de le détourner, de le faire aller à des endroits où il n'est pas censé aller, de le combiner à d'autres systèmes. Cette approche de "bas niveau" s'oppose aux transferts de styles comme DALL·E, où il suffit d'appuyer sur un bouton. Elle implique de comprendre comment le modèle est structuré en couches successives d'appels de fonctions : on peut intercepter une couche, l'inverser, en réinjecter une autre ou certaines informations, etc. » (<a class="interview" style="cursor:pointer" onclick="openWindow('Nicolas Barradeau', 'interviews/Nicolas-Barradeau', event)">Mathieu</a>, 2022)

Pour d'autres personnes, ce n'est pas seulement le modèle statistique qu'il faut travailler, mais également les jeux de données --- ce qui ne va pas sans difficultés, que ce soit au niveau du temps ou des moyens nécessaires. La designer d'interaction Deniz Kurt, interrogée dans le cadre de cet essai (<a class="interview" style="cursor:pointer" onclick="openWindow('Deniz Kurt', 'interviews/Deniz-Kurt', event)">Mathieu</a>, 2022), mentionne l'exemple fictif de la conception d'un site Web musical à l'intention des 18-35 ans, où une IA entraînée sur ce type de données (récoltées spécifiquement) pourrait proposer des voix ou des couleurs adaptées à ce public, ou au contraire produire du décalage pour s'émanciper de propositions trop attendues. Les grands jeux de données ont en effet pour revers d'avoir une approche holistique, et donc homogène. Pour l'artiste et designer Meredith Thomas, la constitution de jeux de données ouvre un nouveau paradigme pour l'informatique dans lequel il n'y a plus besoin de programmer pour obtenir des résultats : « Au lieu de prescrire des règles, vous prescrivez des tâches et vous fournissez des données. » (<a class="interview" style="cursor:pointer" onclick="openWindow('Meredith Thomas', 'interviews/Meredith-Thomas', event)">Mathieu</a>, 2022) Selon lui, la meilleure façon de travailler avec les IA est de former des modèles statistiques à partir de ses propres données (croquis, photos, etc.). Précisant cette idée de jeux de données personnelles, le designer Simone Rebaudengo fait remarquer qu'il n'y a pas besoin, au contraire, d'avoir des données propres et homogènes pour travailler : « Ce qui est intéressant, ce n'est pas d'obtenir de bons résultats, mais plutôt d'explorer d'autres directions. » (<a class="interview" style="cursor:pointer" onclick="openWindow('Meredith Thomas', 'interviews/Meredith-Thomas', event)">Mathieu</a>, 2022)

On comprend alors qu'à vouloir trop faire ou trop bien faire, les IA dominantes échouent à produire des résultats spécifiques ou inattendus. Autrement dit, l'artifice consistant à masquer la complexité technique du système revient à brider ses pratiques et le condamne au registre du service. Quand, au contraire, ces couches sont révélées, alors s'ouvrent des marges de manœuvre pour les artistes et designers. Les designers graphiques du studio Chevalvert (Stéphane Buellet, Arnaud Juracek et Julia Puyo) ont travaillé en ce sens, lors d'un workshop intitulé « Machine Jacking » (Stereolux, 2017), pour détourner des technologies de *machine learning* (reconnaissance vocale, de texte, etc.) de ce pour quoi elles sont habituellement instrumentalisées. En résultent des productions comme une transformation de texte à partir de 26 passages dans des traducteurs automatiques (Hakim Benamara), un système de reconnaissance de textes « vus » par des lunettes de réalité augmentée (Julien Gachadoat), ou une génération de pistes audio et de jaquettes à partir de l'analyse de deux *playlists* Spotify (Margaux Leroy). Selon le studio Chevalvert, se mettre « dans la peau » d'une IA autorise à confronter des « cadrages subjectifs » aux logiques formelles du *machine learning* et à dépasser l'idée d'une substitution de l'humain par la machine. Il faut ainsi déconstruire deux mythes à propos des intelligences artificielles dites créatives : d'une part que l'artiste (ou le·la designer) aurait le contrôle total sur sa production, et d'autre part que la machine serait totalement autonome : une façon plus intéressante de procéder est de jouer avec l'ampleur et l'emplacement du hasard introduit dans des phases de la production.

<a name="jouer-avec-les-aleas-et-limites-de-la-prediction"></a>
#### [↑](#essay) Jouer avec les aléas et limites de la prédiction

Derrière leurs promesses d'efficacité, les technologies du *deep learning* se révèlent rapidement limitées : (select:14)l'automatisation d'un champ ne va pas forcément de pair avec celle d'un autre, et des frictions entre des programmes spécialisés que l'on rassemble mettent en exergue la difficulté voire l'impossibilité de concevoir une intelligence abstraite et globale.(deselect:) Comme y invitent les membres du groupe de travail « AI Anarchies », il importe ainsi d'embrasser «  ce qui échappe à \[leur\] implacable calculabilité. \[\...\] Comment une IA anarchique --- et une adoption de ce qui est anarchique dans l'IA --- pourrait-elle ouvrir de nouvelles possibilités pour la conception de futurs environnements algorithmiques \[\...\] ? » (Herrmann et Vukajlović, 2022)

Si le meilleur garde-fou des IA est leurs limites (Cross, 2020), il peut alors être opportun d'examiner comment elles perturbent la stabilité des codes culturels. Interrogeant le système GPT-3 pour savoir comment les métiers du design vont évoluer avec l'IA, Étienne Mineur s'est vu confronté à une proposition allant dans ce sens : « La façon dont ces programmes réagissent à nos données ne consiste pas à suivre un ensemble de règles de façon linéaire, mais à être fluide, ouvert et organique[^8]. » Fin observateur des *prompts* d'images, il voit ces programmes comme « des robinets à vomi fonctionnant en continu » (<a class="interview" style="cursor:pointer" onclick="openWindow('Étienne Mineur', 'interviews/Etienne-Mineur', event)">Mathieu</a>, 2022). C'est dans leurs aspérités que ces derniers se révèlent intéressants, comme par exemple dans le cas de la requête par Étienne Mineur « d'une lettre A en forme d'huître ». Il s'agit pour lui de contrer les limitations de la base de données et de chercher de l'expressivité dans des accidents graphiques plutôt que dans les codes éprouvés de la science-fiction ou de l'*heroic fantasy*. L'hypothèse d'un retournement intrinsèque à la prédiction et à l'automatisation machinique est explorée dans un article consacré aux conséquences de la culture algorithmique sur la création (« Dada Data », 2018), dans lequel les chercheurs en design Nicolas Nova et Joël Vacheron analysent des productions telles que des *mashups* musicaux ou des couvertures générées par des *bots* (robots) numériques pour mettre en évidence leur étrangeté voire leur absurdité :

« Il ne s'agit pas de remettre en question la primauté humaine en matière de création. Il s'agit davantage de mettre en perspective le spectre de productions et de collaborations engendrées par ces formes d'hybridations. En effet, les esthétiques et la cohérence qui se dégagent de ces productions ne sont jamais pleinement prévisibles, car elles sont toujours le fruit de processus génératifs partiellement ou complètement aléatoires. » (Nova et Vacheron, 2018)

Derrière l'ambition d'un résultat fiable, la complexité des opérations de calcul et la diversité des données de base engendrent souvent des résultats étranges : une logique humaine semble s'en dégager, mais qui est perturbée par des opérations techniques qu'il est impossible d'expliciter. Il en va ainsi du projet *Made in Machina/e* (2018) <a name="fig-11">[\[Fig. 11\]](#ref-fig-11)</a> des designers Simone Rebaudengo et Sami Niemelä, qui travaille les porosités entre le design nordique (usage du bois, de la céramique, lisibilité des fonctions et de la construction, etc.) et l'abondance industrielle des entrepôts chinois de la ville de Shenzhen pour interroger le rôle des designers face à l'apprentissage machinique. Plus concrètement, des composants, matériaux et marchandises disponibles sur le site de e-commerce Alibaba.com sont indexés (« scrapés ») par un programme, transmis à un réseau de neurones « formé » aux principes du design nordique pour générer des *briefs*, lesquels sont ensuite interprétés et construits par un designer (Chih Chiu) puis mis en ligne pour être vendus. Ce métissage, non seulement algorithmique mais aussi humain/machine, suscite des chimères industrielles : par exemple, un contrôleur cinétique en céramique qui peut également servir de vase, ou un lustre à base de *smartphones*. Une telle hybridation interroge directement l'histoire et les fondamentaux du design. Que se passe-t-il lorsque le produit n'est pas créé par un besoin fonctionnel mais par un caprice du marché ? Qui (ou quoi) décide quelles fonctionnalités sont prioritaires, nécessaires, ou même souhaitables ? Ces marchandises existent-elles seulement parce qu'il est possible de les produire ? (Rebaudengo et Niemelä, 2018)

(image: illustrations/Fig11.png caption: Fig.11 - Made in Machina/e)

Comme la prédiction opérée par les IA n'est jamais exacte, celles-ci se révèlent puissantes d'un point de vue humoristique lorsque du sens apparaît maladroitement (car trop littéralement). Le succès du compte Twitter \@weirddalle (« Weird Dall·E Mini Generations », 2022) peut ainsi s'expliquer par la production d'images à la fois trop exactes et trop étranges relativement à la légende (au *prompt*) qui leur est associée visuellement. Leur agencement en neuf cases ainsi que les thématiques convoquées s'inscrivent dans la logique sérielle des mèmes propres à la *pop culture* Web, qui implique des variations entre des motifs (*patterns*) partagés au sein d'une communauté. En interrogeant les notions d'autorialité et de culture « proprement humaine » (Nova et Vacheron, 2018), les technologies du *deep learning* révèlent comment la logique formelle produit de l'illogique, et comment tout calcul nécessite de l'incalculable (comme dans le cas de la Machine de Turing), puisque c'est de l'arrêt du flux que du sens peut surgir.

Un exemple ne faisant pas appel à du *machine learning* montre comment le simple fait de décaler des paramètres peut révéler des mécaniques techniques sous-jacentes. Dans le cadre d'une exposition à la galerie du Centre Saint Charles de l'université Paris 1 Panthéon-Sorbonne (*Deus ex Machina*, commissariat Sophie Fétro, 2015), les designers graphiques Kévin Donnot et Élise Gay (E+K) ont conçu un système de génération d'affiches où un logiciel de fabrication assisté par ordinateur (FAO) détermine le parcours d'un feutre attaché à un *plotter* (traceur) pour qu'il puisse remplir la surface d'une police de caractères. L'usage d'un feutre un peu moins large que prévu fait apparaître des failles à l'intérieur du tracé machinique et crée une matière visuelle singulière. La trace de l'outil s'oppose à l'idée baudelairienne d'une reproduction servile et exacte :

« Quand on réalise un projet, on n'est pas dans une logique de reproduction magique de l'objet, mais plutôt dans une co-création avec la machine. On va chercher à paramétrer la forme à reproduire afin que la machine puisse apporter son empreinte et révéler une certaine forme. Cette notion d'aspérité, notamment quand on mobilise des technologies numériques, est très importante. » (<a class="interview" style="cursor:pointer" onclick="openWindow('Kevin Donnot & Élise Gay', 'interviews/Kevin-Donnot-Elise-Gay', event)">Mathieu</a>, 2022)

<a name="traduire-des-codes-culturels"></a>
#### [↑](#essay) Traduire les codes culturels

(select:9)La mise en évidence de traces et d'aspérités engage une forme de franchise visuelle voire de traduction, si l'on considère que l'acte de traduction menace l'idée d'un original stabilisé une fois pour toutes (Benjamin, \[1923\] 2007).(deselect:) Une quatrième voie d'opportunité serait alors d'associer les notions de traduction (passage d'un code sémantique à un autre code) et de transcodage (transformation du code d'un programme informatique dans un autre langage formel). On touche ici à la tension entre les langages dits « naturels » (mais qui sont construits socialement) et les langages dits « artificiels » ou « formels » (rédigés à l'attention de machines, mais qui reposent en partie sur le langage humain). Fonctionnant à partir de cycles d'ingestion et de digestion de données, le *deep learning* affecte le rapport au langage : avant de concerner les images, sons et vidéos, il s'inscrit dans la longue histoire de la littérature informatique, que prolongent dans une approche plus appliquée des initiatives prometteuses comme Sudowrite (Amit Gupta et James Yu, 2021) ou ChatGPT (OpenAI, 2022), qui rédigent et reformulent des textes à la demande suivant diverses indications : générer une description, changer le ton, résumer ou allonger le contenu, etc. Mais pourrait-on aller plus loin et investir le code informatique pour délimiter et travailler des « codes » culturels impliquant plusieurs modes d'expression ? Comment non pas seulement transférer (à la façon des « transferts de style » visuels des GAN), mais traduire ? Une telle hypothèse a été entrevue au début des années 1990 par le théoricien des médias Vilém Flusser :

« Si je ne peux pas traduire, je ne peux pas comparer. \[\...\] Il est très facile de traduire un traité de chimie, de l'anglais en français, mais traduire un poème de Li Tai Po en français est presque impossible, traduire Mozart en architecture est un grand problème. \[\...\] Peut-être lorsque la science des codes aura fait des progrès plus grands, on pourra faire des familles de codes. Peut-être trouvera-t-on des codes qui peuvent être traduits et d'autres qui ne le peuvent pas. Si on fait un tel catalogue, on comprendra beaucoup de choses sur la situation humaine. Pour le moment ça n'existe pas. Je sais seulement que la théorie de la traduction est \[\...\] une théorie pour les temps nouveaux. C'est un champ d'engagement très grand, parce qu'il ne s'agit pas seulement de traduire de l'anglais en français, il s'agit, par exemple, de traduire Marx en Freud, ou Freud en catholicisme, ou le catholicisme en néopositivisme. C'est là le vrai jeu. » (Flusser, 1973)

Plusieurs initiatives ont exploré la faculté des IA à allier la traduction de « codes » culturels et informatiques. Un premier exemple est celui du catalogue de l'exposition *Neurones, les intelligences simulées* (2020), pour lequel les designers Kévin Donnot et Élise Gay ont imaginé « une espèce d'altérité numérique, une autre intelligence qui puisse participer au livre ou l'annoter » (<a class="interview" style="cursor:pointer" onclick="openWindow('Kévin Donnot & Élise Gay', 'interviews/Kevin-Donnot-Elise-Gay', event)">Mathieu</a>, 2022). Le projet prend comme point de départ un réseau de neurones développé par Alex Graves à l'université de Toronto, à l'origine dédié à la prédiction du trafic routier, et qui eut comme premier champ d'application, à la fin des années 2000, la reconnaissance de l'écriture manuscrite. Ce script a pour objectif d'anticiper le tracé du crayon en fonction des points précédents. Kévin Donnot et Élise Gay ont récupéré les sources du programme et l'ont entraîné avec divers paramètres pour jouer avec ses failles et générer le dessin des titres de l'ouvrage --- « Il y a beaucoup de fois où le réseau de neurones s'emballe et les choses dérivent » (<a class="interview" style="cursor:pointer" onclick="openWindow('Kévin Donnot & Élise Gay', 'interviews/Kevin-Donnot-Elise-Gay', event)">Mathieu</a>, 2022). Un autre script utilisé produit un système d'analyse syntaxique des contenus du catalogue : il analyse chacune des doubles pages et identifie les champs lexicaux récurrents et leurs connexions <a name="fig-12">[\[Fig. 12\]](#ref-fig-12)</a>. Pour Kévin Donnot et Élise Gay, il est important de situer les compétences des designers dans leur capacité à rencontrer et à comprendre des objets techniques, historiques et culturels pour parvenir à les détourner ou à les associer d'une nouvelle façon --- « presque un travail de commissaire d'exposition ». Dans cette visée, les designers ont des jours heureux devant elles·eux, car la montée en puissance des *templates* et des logiques d'automatisation a pour vertu de trier les contextes fertiles : « Y avait-il vraiment de la création dans ces endroits où l'on ne fait que reproduire des codes ? » (<a class="interview" style="cursor:pointer" onclick="openWindow('Kévin Donnot & Élise Gay', 'interviews/Kevin-Donnot-Elise-Gay', event)">Mathieu</a>, 2022)

(image: illustrations/Fig12.png caption: Fig.12 - catalogue de l'exposition *Neurones, les intelligences simulées*)

Plutôt que de partir par défaut d'une suite logicielle comme Adobe éprouvée mais épuisée par le marché, il est plus judicieux de se demander quelle technique fait sens. Le spectre des IA, si on les considère dans une approche ouverte, se révèle assez large pour explorer des traductions de codes culturels. Le designer Simone Rebaudengo voit ainsi dans le *machine learning* une façon non pas de reproduire des codes, mais d'explorer le spectre entre deux codes (<a class="interview" style="cursor:pointer" onclick="openWindow('Simone Rebaudengo', 'interviews/Simone-Rebaudengo', event)">Mathieu</a>, 2022). On pourrait par exemple donner comme consigne à une machine d'appliquer un style à un objet pour lui injecter 40 % du designer Alvar Aalto, ou 30 % de Aalto et 40 % de quelqu'un d'autre, et naviguer dans l'espace étrange que cela propose pour identifier des continuités inattendues entre des designers. Toujours selon Simone Rebaudengo, les poussées techniques des modèles statistiques de langage comme Google LaMDA (Language Model for Dialogue Applications, 2020) autorisent désormais à converser non plus seulement avec n'importe qui, mais avec n'importe quoi, comme par exemple avec Pluton qui va alors « répondre » du point de vue d'une planète. De nouveaux types de traductions pourraient apparaître grâce aux IA, comme s'enthousiasme Cristóbal Valenzuela, le cofondateur du logiciel Runway ML (2019) dédié à l'édition de vidéos grâce au *machine learning*. Par exemple, des images 2D peuvent être transformées en 3D, ou des images en son. Ces « croisements de fonctions médiatiques » (<a class="interview" style="cursor:pointer" onclick="openWindow('Cristóbal Valenzuela', 'interviews/Cristobal-Valenzuela', event)">Mathieu</a>, 2022) pourraient nourrir les disciplines et domaines de recherche de la création. Ce passage d'un média à un autre a été mis en évidence dans ce qui pourrait être un des premiers ouvrages de poésie en langue française écrits par un réseau de neurones. Le recueil *Machines Upon Every Flower* des artistes Gregory Chatonsky et Karmel Allison (Chatonsky et Allison, 2018) associe deux programmes de *machine learning* pour générer des poèmes à partir de mots uniques, puis des images à partir de ces poèmes. Ce travail par phases et par associations invite à replacer les IA dans un écosystème plus large associant humains et non humains. Critiquant les fantasmes d'une automatisation totale de la création, Gregory Chatonsky pose le constat suivant : « L'autonomie sous-tend une logique de l'absolu, de la séparation dont la forme matérielle est l'instrumentalisation de tout le reste comme ressource. Or rien n'est autonome, tout est dépendant d'un tissu d'autres choses. Quel est le tissu de l'IA[^9] ? »

<a name="inventer-de-nouveaux-modes-de-collaboration"></a>
#### [↑](#essay) Inventer de nouveaux modes de collaboration

(select:13)Cette attention portée au tissage entre humains et systèmes techniques nous amène à formuler un cinquième axe de travail avec les réseaux de neurones pouvant intéresser les designers.(deselect:) Il consiste à ne plus envisager les IA comme des machines de création (détachées symboliquement des contingences matérielles) mais comme des étapes de production. On pourrait par exemple utiliser le *deep learning* pour esquisser ou analyser des amorces d'idées et les comparer à l'existant, dans une stratégie d'aide à la décision et non pas d'imitation ou d'automatisation totale. La vitesse d'exécution du *machine learning*, tout d'abord, change les méthodes de travail du design. Le designer Boyd Rotgans travaille ainsi à l'élaboration d'une plateforme contenant 60 heures de vidéos, lesquelles peuvent être « résumées » à la demande dans un court clip suivant telle ou telle requête (choix d'une personne, d'une couleur, etc.) (<a class="interview" style="cursor:pointer" onclick="openWindow('Boyd Rotgans', 'interviews/Boyd-Rotgans', event)">Mathieu</a>, 2022), ce qui pourrait à terme être appliqué à d'autres médias. Cristóbal Valenzuela voit quant à lui dans les IA la possibilité d'itérer (de répéter un processus) à grande échelle. Selon lui, grâce au *machine learning*, les designers pourraient « nourrir » les programmes avec leurs productions et apprendre à décomposer leur travail afin qu'ils·elles puissent itérer non pas seulement 10 fois mais plus de 100 fois par jour (<a class="interview" style="cursor:pointer" onclick="openWindow('Boyd Rotgans', 'interviews/Boyd-Rotgans', event)">Mathieu</a>, 2022). Les IA peuvent aussi aider à rassembler plus vite des éléments provenant de domaines d'expertises hétérogènes et réduire la barrière de compréhension.

Plus fondamentalement, pour le designer Rifke Sadleir, « nous devrions nous débarrasser de l'idée de nous séparer des machines. Les machines ne sont pas des humains mais des extensions de nos propres esprits, car ce qui en sort est une interprétation de ce que nous y avons mis » (<a class="interview" style="cursor:pointer" onclick="openWindow('Rifke Sadleir', 'interviews/Rifke-Sadleir', event)">Mathieu</a>, 2022). La designer Nadia Piet voit ainsi dans les IA la possibilité de devenir des « partenaires créatifs » (<a class="interview" style="cursor:pointer" onclick="openWindow('Nadia Piet', 'interviews/Nadia-Piet', event)">Mathieu</a>, 2022), où la création résulte de va-et-vient avec des machines qui permettent d'explorer rapidement telle ou telle esthétique, ou de générer des centaines de prototypes à la demande. Une telle hypothèse a été mise en œuvre par le studio Oio (dont fait partie Simone Rebaudengo), qui se présente sur son site Web comme étant « composé de *bots*, d'humains et de machines ». Plus précisément, le studio comprend officiellement un acteur non humain, Roby, qui agit comme un·e créateur·trice artistique. À l'origine, ce *bot* Discord était utilisé pour explorer de nouveaux produits et idées au sein de l'agence. Il est désormais considéré comme un·e collaborateur·trice à part entière (à rebours des idées, assez vite limitées, d'outil et d'automatisation). Roby possède son propre compte Instagram, et « vit » dans un micro-contrôleur Raspberry Pi. Contrairement à l'approche anthropomorphique d'une bonne partie de l'informatique, ce qui intéresse Simone Rebaudengo dans ce type de démarche est de « créer une intelligence qui n'est pas aussi intelligente que celle d'un humain » --- à l'image de sa série d'objets *Domesticating Intelligence* (Rebaudengo, 2016), qui a par exemple donné lieu à un programme s'apparentant à un oiseau (Google Creative Lab, 2017). Il est impossible de lui parler ; il faut interagir avec lui par le son et par des gestes, le sortir, etc., ce qui offre entre autres des perspectives nouvelles sur la notion de vie privée.

Cet intérêt pour d'autres modalités de psychisme a été passé sous silence par les intelligences artificielles et par leur incarnation dans des objets comme les assistants vocaux. D'autres rapports aux machines mériteraient d'être explorés, y compris si l'on reste dans le registre humain (Audry, 2019). Simone Rebaudengo invite ainsi à se poser des questions du type : « Est-ce un outil d'assistance ? Est-ce un logiciel comme Photoshop ? Un collègue de travail ? Un·e stagiaire ? Est-ce juste un gars bizarre qui a son propre point de vue ? » (<a class="interview" style="cursor:pointer" onclick="openWindow('Simone Rebaudengo', 'interviews/Simone-Rebaudengo', event)">Mathieu</a>, 2022) Cette approche a été mise en œuvre par l'artiste Raphaël Bastide dans sa performance *Twins* (2016), où il s'est enfermé dans une galerie durant trois jours pour développer des intelligences artificielles : la performance « est devenue une étude sur la paternité numérique (la relation entre le développeur et ses avatars intelligents) et sur les capacités émotionnelles des non-humains. Les recherches sur les réseaux de neurones artificiels et les progrès de l'apprentissage automatique permettent d'élargir et d'affiner notre connaissance de notre propre espèce et du cerveau humain. » (Bastide, 2016)

(image: illustrations/Fig13.png caption: Fig.13 - Thinking Machines)

À suivre ce type de démarche, les IA pourraient alors devenir non plus seulement des assistantes, mais des collaboratrices (Audry, 2019), laissant ainsi entrevoir de profondes reconfigurations dans les méthodes de design. Cette hypothèse a été explorée à la HEAD -- Genève dans le cadre d'un workshop en Master Media Design coordonné par Alexia Mathieu, Jürg Lehni et Douglas Edric Stanley. Le projet collectif qui en résulte, *Thinking Machines* (2020) <a name="fig-13">[\[Fig. 13\]](#ref-fig-13)</a>, a pour objectif de prendre le contre-pied du remplacement des designers par des machines (Masure, 2020, p. 128-131). Plus précisément, *Thinking Machines* prend la forme d'un système de publication de récits sur mesure, qui utilise des cartes perforées, des générateurs de texte, des ombres chinoises, la reconnaissance vocale, l'apprentissage automatique et des outils de publication Web pour construire des récits singuliers. En mélangeant plusieurs époques de l'informatique, depuis ses débuts jusqu'aux réseaux de neurones du *deep learning*, « l'ancien devient le nouveau qui devient l'ancien[^10] ». Ce processus laisse entrevoir ce que pourrait être le studio de design du futur : moins un lieu où définir des solutions et des formes closes qu'un laboratoire où mélanger et faire bifurquer des techniques <a name="fig-14">[\[Fig. 14\]](#ref-fig-14)</a>.

(image: illustrations/Fig14.png caption: Fig.14 - Thinking Machines)

<a name="conclusion"></a>
### [↑](#essay) Conclusion

Ces quelques perspectives sur la situation et l'avenir du design face à l'apprentissage automatique amènent, en conclusion, à préciser la signification du titre de cet ouvrage, « design sous artifice », que nous comprenons comme la volonté de complexifier le fonctionnement d'un système au profit de sa rentabilité. Si cette tendance n'est pas propre aux IA, elle se voit poussée à un autre niveau par la multiplication des couches nécessaires aux opérations du *deep learning*. Cette réduction du design à une voie à sens unique présente comme risque majeur de ne produire que du stéréotype et de l'homogène, où tout problème doit être modélisé et verbalisé pour exister. Ces technologies tendent à imposer leurs valeurs dominantes et à restreindre voire à confisquer les imaginaires du futur --- qu'ils soient dominés par la vision occidentale, par celle du genre masculin, ou par celle de corps et de psychismes parfaitement valides. Le fantasme de la toute-puissance d'une machine asservie au commandement humain renvoie à des logiques plus anciennes de domination ou d'asservissement qu'il est urgent de déconstruire : il s'agit de repenser nos relations aux technologies et de passer d'une compréhension binaire (domination/exécution) de la machine à l'appréhension d'une complexité et des vulnérabilités. Le travail devient alors moins vertical qu'horizontal, plus collaboratif qu'instrumental.

Il faut constater, par exemple, que la modalité dominante des IA aura laissé de côté l'idée de simuler des psychismes défaillants (c'est-à-dire humains) pour lui préférer la vision normative d'un cerveau fonctionnant en continu (et ne faisant que fonctionner). Alan Turing, dans sa préfiguration des ordinateurs, avait pourtant démontré que tout calcul implique une zone d'incalculable et que toute machine, aussi performante soit-elle, finira par planter. Chercher à combler ou à masquer ces temps d'arrêt a pour conséquences d'interdire la production de nouvelles significations et de condamner ces systèmes au registre de la reproduction. Déliée de sa faculté à suspendre le flux, et donc à surprendre, la technique instrumentalisée ne peut être qu'un spectacle, qu'un artifice. La première occurrence historique du terme « artifice » (*artefice*) renvoie à l'« art de tromper » et à un « moyen habile et plus ou moins trompeur », à laquelle s'ajoute plus tardivement l'idée d'un engin préparé pour une fête et destiné à éclairer (au sens figuré : « ce qui éblouit ») (Rey, 2010). Ce n'est pas la moindre des tromperies d'avoir nommé « intelligence artificielle » l'artifice consistant à assimiler les intelligences simulées à la faculté de « lire entre les lignes » (*inter-legere*)[^11] --- ce qu'une machine ne pourra jamais faire.

Les technologies du *deep learning* n'ont pas pour fatalité de s'inscrire dans le registre de l'artifice et gagneraient au contraire à devenir des « intelligences de l'artificiel ». Si le terme d'artificiel peut sembler similaire à celui d'artifice, « il n'a qu'exceptionnellement signifié *trompeur* ou *insidieux* \[\...\] Il s'est opposé à naturel, en conservant l'idée d'activité humaine réglée, de méthode » (Rey, 2010). Désignant, au sens fort, ce qui est produit par la technique, l'artificiel peut être cultivé dans différentes directions, comme y invite le designer Ezio Manzini pour qui l'action humaine et la transformation continue des environnements de vie font que la distinction entre artificiel et naturel ne tient plus : l'artificiel est devenu une « seconde nature » dont les designers ont pour tâche de façonner le destin. L'uniformité engendrée par les applications médiatiques du *deep learning* n'est pas une fatalité et il leur appartient de penser ce que pourrait être une « écologie de l'artificiel ». Plutôt que de chercher à reprendre la main (« le système technique n'est pas un instrument \[ou\] un moyen sur lequel une volonté subjective a totalement prise pour arriver à une fin bien précise ») (Manzini, \[1990\] 1991, p. 51), il est plus intéressant de cheminer dans les couches et paramètres du *machine learning* et de prendre plaisir à s'y perdre : « Plus le système technique étend et gagne en complexité, plus il emprunte des voies dont il est impossible de contrôler l'issue ; d'où la création d'un monde artificiel inconnu qu'il nous faut explorer pour en connaître les qualités et les lois. » (Manzini, \[1990\] 1991, p. 52) En somme, l'apprentissage automatique n'est pas une tendance à rejeter de façon univoque : une intelligence de l'artificiel consiste au contraire à abandonner la simulation servile et schématique du psychisme humain pour faire place à l'altérité et aux aspérités des machines.

<a name="bibliographie"></a>
### [↑](#essay) Bibliographie

- Audry Sofian, *Art in the Age of Machine Learning,* Cambridge, MIT Press, 2021

- Baudelaire Charles, « Le public moderne et la photographie » \[1859\], *Études photographiques*, mai 1999, [journals.openedition.org/etudesphotographiques/185](http://journals.openedition.org/etudesphotographiques/185)

- Barrat Robbie, « Balenciaga AI », *GitHub*, 2018, [robbiebarrat.github.io/balenciaga.html](http://robbiebarrat.github.io/balenciaga.html)
- Bastide Raphaël, « Twins », 2016, [www.raphaelbastide.com/twins](http://www.raphaelbastide.com/twins)
- Benhamou Yaniv, « Art génératif, *prompt art* et intelligence artificielle : que dit le droit d'auteur ? », *Heidi News*, octobre 2022, [www.heidi.news/cyber/art-generatif-prompt-art-et-intelligence-artificielle-que-dit-le-droit-d-auteur](http://www.heidi.news/cyber/art-generatif-prompt-art-et-intelligence-artificielle-que-dit-le-droit-d-auteur)
- Benjamin Walter, « La tâche du traducteur » \[1923\], dans : *Œuvres 1*, trad. de l'allemand par Maurice de Gandillac, Rainer Rochlitz et Pierre Rusch, Paris, Gallimard, coll. Folio essais, 2007
- Benjamin Walter, « L'auteur comme producteur » \[1934\], dans : *Essais sur Brecht*, trad. de l'allemand par Paul Laveau, Paris, François Maspero, 1969
- Bratton Benjamin H., « The Black Stack », *E-flux*, n° 53, mars 2014, [www.e-flux.com/journal/53/59883/the-black-stack](http://www.e-flux.com/journal/53/59883/the-black-stack)
- Bush Vannevar, « Comme nous pourrions penser » \[« As We May Think »\], *The Atlantic Monthly*, vol. 176, n° 1, juillet 1945
- Cardon Dominique, *À quoi rêvent les algorithmes ? Nos vies à l'heure des big data*, Paris, Seuil, 2015
- Cardon Dominique, Jean-Philippe Cointet, Antoine Mazières, « La revanche des neurones », *Réseaux*, n° 211, novembre 2018, [neurovenge.antonomase.fr](http://neurovenge.antonomase.fr)
- Casilli Antonio A., *En attendant les robots. Enquête sur le travail du clic*, Paris, Seuil, coll. « La Couleur des idées », 2019
- Cassou-Noguès Pierre, « Le temps et la mémoire, l'homme et la machine : autour de la cybernétique », *Intellectica*, n° 52, 2009, [www.persee.fr/doc/intel_0769-4113_2009_num_52_2_1203](http://www.persee.fr/doc/intel_0769-4113_2009_num_52_2_1203)
- Chatonsky Grégory, Allison Karmel, *Machines Upon Every Flower*, Montréal, Anteism, 2018, [www.anteism.com/shop/machines-upon-every-flower](http://www.anteism.com/shop/machines-upon-every-flower)
- Chazal Gérard, *Le miroir automate. Introduction à une philosophie de l'informatique*, Paris, Champ Vallon, 1998
- Christie's, « Is artificial intelli-gence set to become art's next medium ? », *Christies.com*, décembre 2018, [www.christies.com/features/A-collaboration-between-two-artists-one-human-one-a-machine-9332-1.aspx](http://www.christies.com/features/A-collaboration-between-two-artists-one-human-one-a-machine-9332-1.aspx)
- Crawford Kate, *Contre-atlas de l'intelligence artificielle. Les coûts politiques, sociaux et environnementaux de l'IA* \[2021\], trad. de l'anglais (Australie) par Laurent Bury, Paris, Zulma, 2022
- Crawford Kate, Joler Vladan, « Anatomy of an AI System: The Amazon Echo As An Anatomical Map of Human Labor, Data and Planetary Resources », AI Now Institute et Share Lab, 2018, [www.anatomyof.ai](http://www.anatomyof.ai)
- Crawford Kate, Paglen Trevor, « Excavating AI. The Politics of Images in Machine Learning Training Sets », 2019, [www.excavating.ai](http://www.excavating.ai)
- Cross Tim, « An understanding of AI's limitations is starting to sink in », *The Economist*, 11 juillet 2020, [www.economist.com/technology-quarterly/2020/06/11/an-understanding-of-ais-limitations-is-starting-to-sink-in](http://www.economist.com/technology-quarterly/2020/06/11/an-understanding-of-ais-limitations-is-starting-to-sink-in)
- Ertzscheid Olivier, « Trump, Google, l'idiot utile, les architectures techniques toxiques et le meilleur des algorithmes possibles », *Affordance.info*, décembre 2018, [affordance.info/mon_weblog/2018/12/meilleur-algorithmes-possibles-trump-idiot.html](http://affordance.info/mon_weblog/2018/12/meilleur-algorithmes-possibles-trump-idiot.html)
- Ertzscheid Olivier, « Une question de génération. Vers un capitalisme sémiotique », Framasoft, *Affordance*, octobre 2022, [affordance.framasoft.org/2022/10/question-generation-capitalisme-semiotique/](http://affordance.framasoft.org/2022/10/question-generation-capitalisme-semiotique/)
- Flusser Vilém, *Le monde codifié*, Paris, Institut de l'Environnement, 1973. Tiré à part (texte inédit), p. 22-23. Document conservé aux archives Vilém Flusser, Universität der Künste Berlin
- Herrmann Clara, Vukajlović Nataša (dir.), « AI Anarchies », Berlin, Akademie der Künste/ Junge Akademie, Autumn School, octobre 2022, [www.aianarchies.net/about](http://www.aianarchies.net/about)
- Hinton Geoffrey E., Osindero Simon, Teh Yee-Whye, Cambridge, MIT Press, *Neural Computation*, vol. 18, n° 7, juillet 2006, https://10.1162/neco.2006.18.7.1527
- Huyghe Pierre-Damien, « Art et mécanique », *Le Portique*, 1999, [journals.openedition.org/leportique/296](https://journals.openedition.org/leportique/296)
- Huyghe Pierre-Damien, « De la mécanisation au design », Saint-Étienne, ESADSE, *Azimuts*, n° 39, 2013, [www.revue-azimuts.fr/numeros/39/de-la-mecanisation-au-design](http://www.revue-azimuts.fr/numeros/39/de-la-mecanisation-au-design)
- Huyghe Pierre-Damien, *Numérique. La tentation du service*, Paris, B42, 2022
- ING, « Rembrandt goes digital », *ING.com*, avril 2016, [www.ing.com/Newsroom/News/Rembrandt-goes-digital-.htm](http://www.ing.com/Newsroom/News/Rembrandt-goes-digital-.htm)
- Jorion Paul, « Turing, ou la tentation de comprendre », *L'Homme*, n° 153, janvier-mars 2000, [http://journals.openedition.org/lhomme/18](http://journals.openedition.org/lhomme/18)
- Kauffman Jordan, « Dessiner avec l'ordinateur dans les années soixante : le design et ses pratiques à l'aube de l'ère numérique », trad. de l'anglais par Marie-Luce Kauffman, *Livraisons de l'histoire de l'architecture*, 2016, n° 32, p. 105-123, reproduit à [www.problemata.org/fr/articles/640](http://www.problemata.org/fr/articles/640)
- Keller Milo, Gunti Claus, Amoser Florian (dir.), *Automated Photography*, Lausanne, Ecal, 2021
- Klein Judy L., Lemov Rebecca, Gordin Michael D., Daston Lorraine, Erickson Paul, Sturm Thomas, *Quand la raison faillit perdre l'esprit. La rationalité mise à l'épreuve de la Guerre froide* \[2013\], trad. de l'anglais par Jean-François Caro, Bruxelles, Zones Sensibles, 2015
- Kurenkov Andrey, « A "Brief" History of Neural Nets and Deep Learning », *AndreyKurenkov.com*, décembre 2015, [www.andreykurenkov.com/writing/ai/a-brief-history-of-neural-nets-and-deep-learning](http://www.andreykurenkov.com/writing/ai/a-brief-history-of-neural-nets-and-deep-learning)
- Lacan Jacques, *Le Séminaire, Livre II, Le moi dans la théorie de Freud et dans la technique de la psychanalyse* (1954--1955), Paris, Seuil, coll. « Champ freudien », 1978
- Lassègue Jean, « Des grilles et des rubans. Les machines formelles d'Alan Turing », entretien avec Kévin Donnot et Anthony Masure, Paris, B42, *Back Office*, n° 2, « Penser, classer, représenter », 2018, [www.revue-backoffice.com/numeros/02-penser-classer-representer/jean-lassegue-grilles-rubans](http://www.revue-backoffice.com/numeros/02-penser-classer-representer/jean-lassegue-grilles-rubans)
- Le Cun Yann, Boser Bernhard, Denker John S., Henderson Donnie, « Backpropagation Applied to Handwritten Zip Code Recognition », *Neural Computation*, vol. 1, n° 4, hiver 1989, https://doi.org/10.1162/neco.1989.1.4.541
- Lovink Geert, « Proposition on Peak Data » Amsterdam, Institute of Network Cultures, *Net Critique*, avril 2022, [www.networkcultures.org/geert/2022/04/07/proposition-on-peak-data](http:/:www.networkcultures.org/geert/2022/04/07/proposition-on-peak-data)
- Maeda John, « Time-graphics », « Reactive--graphics », « Metadesigning », série de trois essais, Tokyo, Kabushiki Kaisha, *MdN*, 1995, [www.maedastudio.com/1995/mdn3/index.php](http://www.maedastudio.com/1995/mdn3/index.php)
- Manovich Lev, Arielli Emanuele, *Artificial Aesthetics: A Critical Guide to AI, Media and Design*, ouvrage *open access*, en cours d'écriture, 2021
- Manovich Lev, *Cultural Analytics*, Cambridge, The MIT Press, 2020
- Manzini Ezio, *Artefacts. Vers une écologie de l'environnement artificiel* \[1990\], trad. de l'italien par Adriana Pilia, Paris, Centre Georges Pompidou, CCI, coll. « Les Essais », 1991
- Masure Anthony, « Résister aux boîtes noires. Design et intelligence artificielle », Paris, PUF *Cités*, n° 80, « L'intelligence artificielle : enjeux éthiques et politiques », dir. Vanessa Nurock, décembre 2019, [www.anthonymasure.com/articles/2019-12-resister-boites-noires-design-intelligences-artificielles](http://www.anthonymasure.com/articles/2019-12-resister-boites-noires-design-intelligences-artificielles)
- Masure Anthony, « Pour un design alternatif de l'IA ? », entretien avec Douglas Edric Stanley et Jürg Lehni, *Multitudes*, n° 78, « Cultivons nos intelligences artificielles », 2020, [www.anthonymasure.com/articles/2020-04-design-alternatif-ia](http://www.anthonymasure.com/articles/2020-04-design-alternatif-ia)
- Masure Anthony, « Des premières interfaces graphiques aux intelligences artificielles du *deep learning* : vers un design à sens unique ? », dans : Fenoglio Antoine, Fleury Cynthia (dir.), *Soigner le monde. Design et éthique du care*, Paris, PUF, 2023a
- Masure Anthony, « Promesses, limites, bifurcations : du "design pour la vie" aux angles morts du numérique, dans : Citton Yves, Lechner Marie, Masure Anthony (dir.), *Angles morts du numérique ubiquitaire. Un glossaire critique et amoureux*, Paris, ArTeC, 2023b
- Mathieu Alexia, entretiens réalisés le cadre du projet de recherche «  Design et *machine learning* : l'automatisation au pouvoir ? », HEAD -- Genève (HES-SO), janvier -- décembre 2022, [www.design-machine-learning.ch](http://www.design-machine-learning.ch)
- McClymont Alistair, Fass John, 'Of Machines Learning to See Lemon', *Alistair McClymont*, 2018, [www.alistairmcclymont.com/artwork/of-machines-learning-to-see-lemon](http://www.alistairmcclymont.com/artwork/of-machines-learning-to-see-lemon)
- McCarthy John, Minsky Marvin L., Rochester Nathaniel, Shannon Claude E., « A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence » \[1955\], *AI Magazin*e, vol. 27, n° 4, hiver 2006, [www.doi.org/10.1609/aimag.v27i4.1904](http://www.doi.org/10.1609/aimag.v27i4.1904)
- Menghini Mathieu, « Création ou production ? », Genève, *Le Courrier*, 2021, [www.lecourrier.ch/2021/08/06/creation-ou-production](http://www.lecourrier.ch/2021/08/06/creation-ou-production)
- Minsky Marvin, Papert Seymour, *Perceptrons: an introduction to computational geometry*, Boston, MIT Press, 1969
- Moholy-Nagy László, « Production -- Reproduction » \[1922\], dans : *Peinture Photographie Film et autres écrits sur la photographie*, trad. de l'anglais par Jean Kempf et Gérard Dallez, Paris, Folio, 2007
- Morozov Evgeny, *Pour tout résoudre cliquez ici. L'aberration du solutionnisme technologique* \[2013\], trad. de l'anglais par Marie-Caroline Braud, Limoges, Fyp, 2014
- Morris William, « La vie ou la mort de l'art » \[1884\], trad. de l'anglais, *Le Socialiste*, 19 juin 1904, reproduit à [www.designluminy.com/william-morris-la-vie-ou-la-mort-de-lart](http://www.designluminy.com/william-morris-la-vie-ou-la-mort-de-lart)
- Moulier-Boutang Yann, Kyrou Ariel, « Mama IA Mamamouchi. Le dynamitage de 7 idées reçues pour en finir avec le Bourgeois numérique, ce Monsieur Jourdain de l'intelligence artificielle », *Multitudes*, n° 72, octobre 2018, [www.cairn.info/revue-multitudes-2018-3-page-7.htm](http://www.cairn.info/revue-multitudes-2018-3-page-7.htm)
- Nova Nicolas, Vacheron Joël, « Dada Data. Une introduction aux cultures algorithmiques », Paris, B42, *Back Office*, n° 2, 2018, [www.revue-backoffice.com/numeros/02-penser-classer-representer/nova-vacheron-dada-data](http://www.revue-backoffice.com/numeros/02-penser-classer-representer/nova-vacheron-dada-data)
- Perriault Jacques, « Effet diligence, effet serendip et autres défis pour les sciences de l'information », Paris, CNRS, ENST, UIUC, UCSD, colloque international « Les pratiques collectives distribuées sur Internet », 19-20 septembre 2000
- Posture Julien, « If You're Worried About DALL·E Replacing Illustrators, You Don't Understand The Power of Illustration », *Aiga Eye on Design*, juillet 2022, [www.eyeondesign.aiga.org/if-youre-worried-about-dall%c2%b7e-replacing-illustrators-you-dont-understand-the-power-of-illustration](http://www.eyeondesign.aiga.org/if-youre-worried-about-dall%c2%b7e-replacing-illustrators-you-dont-understand-the-power-of-illustration)
- Rebaudengo Simone, « Domesticating Intelligence », *Medium*, juillet 2016, [www.medium.com/@fishandchipsing/domesticating-intelligence-f90067bd8e64](http://www.medium.com/@fishandchipsing/domesticating-intelligence-f90067bd8e64)
- Rey Alain (dir.), « Artifice », dans : *Dictionnaire historique de la langue française, Dictionnaire historique de la langue française*, Paris, Le Robert, 2010
- Rosenblueth Arturo, Wiener Norbert, Bigelow Julian \[1943\], « Comportement, but et téléo-logie », reproduit dans : Aline Pélissier et Alain Tête, *Sciences cognitives. Textes fondateurs* *(1943--1950)*, Paris, PUF, 1995
- Saint-Jevin Alexandre, « La "machine électronique" de Lacan : Alan Turing chez les psychanalystes », *L'évolution psychiatrique*, n° 82, 2017, [www.doi.org/10.1016/j.evopsy.2016.12.001](http://www.doi.org/10.1016/j.evopsy.2016.12.001)
- Saint-Jevin Alexandre, « Sur la trace de l'humain dans les "objets" de design », *Non-Fiction*, mars 2018, [www.nonfiction.fr/article-9264-sur-la-trace-de-lhumain-dans-les-objets-de-design.htm](http://www.nonfiction.fr/article-9264-sur-la-trace-de-lhumain-dans-les-objets-de-design.htm)
- Saint-Jevin Alexandre, « De la machine universelle de Turing à celle de Lacan, en passant par l'appareil psychique freudien », dans : *La machine psychanalytique. Théorie de la machine lacanienne*, Presses universitaires de Dijon, 2019
- Saulnier Boris, « Compte-rendu de l'ouvrage de John Von Neumann *L'ordinateur et le cerveau \[1955--1956\] »*, mars 2003, [www.boris.saulnier.free.fr/DOCS/200303_Saulnier_OrdiCerveau.pdf](http://www.boris.saulnier.free.fr/DOCS/200303_Saulnier_OrdiCerveau.pdf)
- Stereolux, « Design graphique et intelligence artificielle : vers un design algorithmique ? », Nantes, *Stereolux.org*, octobre 2017, [www.stereolux.org/blog/design-graphique-et-intelligence-artificielle-vers-un-design-algorithmique](http://www.stereolux.org/blog/design-graphique-et-intelligence-artificielle-vers-un-design-algorithmique)
- Steyerl Hito, « In Defense of the Poor Image », *E-Flux*, novembre 2009, [www.e-flux.com/journal/10/61362/in-defense-of-the-poor-image](http://www.e-flux.com/journal/10/61362/in-defense-of-the-poor-image)
- Turing Alan M., « Théorie des nombres calculables, suivie d'une application au problème de la décision » \[« On Computable Numbers, with an Application to the Entscheidungsproblem », 1936\], trad. de l'anglais par Julien Basch et Patrice Blanchard dans : *La Machine de Turing*, édition dirigée par Jean-Yves Girard, Paris, Seuil, coll. « Sciences », 1995
- Turing Alan M., « Lecture on the Automatic Computing Engine », exposé à la London Mathematical Society, 20 février 1947, reproduit dans : Brian Jack Copeland (dir.), *The Essential Turing-Seminal Writings in Computing, Logic, Philosophy, Artificial Intelligence*, New York, Oxford University Press, 2004
- Turing Alan M., « Les ordinateurs et l'intelligence » \[« Computing machinery and intelligence », 1950\], trad. de l'anglais par Julien Basch et Patrice Blanchard, dans : Jean-Yves Girard (dir.), *La Machine de Turing*, Paris, Seuil, coll. « Sciences », 1995
- Von Neumann John, *L'ordinateur et le cerveau* \[*The Computer and the Brain*, 1958\], trad. de l'anglais par Pascal Engel, Paris, Flammarion, 1996
- Von Neumann John, « General and logical theory of automata » \[1948\], dans : Abraham Haskel Taub (dir.), *Collected Works*, Oxford, Pergamon Press, 1963, vol. V., « Design of Computers, Theory of Automata and numerical Analysis », extrait trad. de l'anglais par Pierre Cassou-Noguès dans : « Le temps et la mémoire, l'homme et la machine : autour de la cybernétique », *Intellectica*, n° 52 « Sport de haute performance et cognition », 2009, p. 141-159, [www.persee.fr/doc/intel_0769-4113_2009_num_52_2_1203](http://www.persee.fr/doc/intel_0769-4113_2009_num_52_2_1203)
- Watson John Broadus, « Psychology as the Behaviorist Views it », *Psychological Review*, n° 20, 1913
- Wiener Norbert, *La cyber-nétique. Information et régulation dans le vivant et la machine* \[*Cybernetics or Control and Communication in the Animal and the Machine*, 1948\], trad. de l'anglais par Ronan Le Roux, Robert Vallée et Nicole Vallée-Lévi, Paris, Seuil, 2014
- Wiener Norbert, *Cybernétique et société. L'usage humain des êtres humains* \[*The Human Use of Human Beings. Cybernetics and Society*, 1950-1954\], trad. de l'anglais par Pierre-Yves Mistoulon et Ronan le Roux, Paris, Point, 2014

<a name="illustrations"></a>
### [↑](#essay) Illustrations

- <a href="#fig-1" name="ref-fig-1">[Fig. 1]</a> © Collectif Obvious <a href="#fig-1" class="footnote-backref">↩</a>
- <a href="#fig-2" name="ref-fig-2">[Fig. 2]</a> © ING, Microsoft, J. Walter Thompson <a href="#fig-2" class="footnote-backref">↩</a>
- <a href="#fig-3" name="ref-fig-3">[Fig. 3]</a> © Cary Gabriel Costello <a href="#fig-3" class="footnote-backref">↩</a>
- <a href="#fig-4" name="ref-fig-4">[Fig. 4]</a> © Cristobal Valenzuela <a href="#fig-4" class="footnote-backref">↩</a>
- <a href="#fig-5" name="ref-fig-5">[Fig. 5]</a> © Lev Manovich <a href="#fig-5" class="footnote-backref">↩</a>
- <a href="#fig-6" name="ref-fig-6">[Fig. 6]</a> © Apple <a href="#fig-6" class="footnote-backref">↩</a>
- <a href="#fig-7" name="ref-fig-7">[Fig. 7]</a> © Shane McGeehan <a href="#fig-7" class="footnote-backref">↩</a>
- <a href="#fig-8" name="ref-fig-8">[Fig. 8]</a> © Fashion MNIST <a href="#fig-8" class="footnote-backref">↩</a>
- <a href="#fig-9" name="ref-fig-9">[Fig. 9]</a> © Mario Klingemann <a href="#fig-9" class="footnote-backref">↩</a>
- <a href="#fig-10" name="ref-fig-10">[Fig. 10]</a> © Alistair McClymont <a href="#fig-10" class="footnote-backref">↩</a>
- <a href="#fig-11" name="ref-fig-11">[Fig. 11]</a> © Simone Rebaudengo, Sami Niemelä <a href="#fig-11" class="footnote-backref">↩</a>
- <a href="#fig-12" name="ref-fig-12">[Fig. 12]</a> © E+K (Élise Gay et Kevin Donnot) <a href="#fig-12" class="footnote-backref">↩</a>
- <a href="#fig-13" name="ref-fig-13">[Fig. 13]</a> © HEAD -- Genève (Michel Giesbrecht) <a href="#fig-13" class="footnote-backref">↩</a>
- <a href="#fig-14" name="ref-fig-14">[Fig. 14]</a> © HEAD -- Genève (Michel Giesbrecht) <a href="#fig-14" class="footnote-backref">↩</a>

<a name="crédits"></a>
### [↑](#essay) Crédits

**Anthony Masure** est responsable de la recherche et professeur associé à la Haute école d'art et de design de Genève (HEAD -- Genève, HES--SO). Ses recherches actuelles portent sur les implications pour le design des intelligences artificielles et des technologies blockchain. Il a cofondé les revues *Back Office et Réel-Virtuel* et est l'auteur de l'essai *Design et humanités numériques* (Éd. B42, 2017). Il est membre fondateur de Hint3rland (2022), un studio de création pour le monde décentralisé. [www.anthonymasure.com](http://www.anthonymasure.com)

HEAD -- Publishing, 2023
Textes sous licence libre
CC BY--SA

Titre : Design sous artifice : la création au risque du *machine learning*
Auteur : Anthony Masure
Collection Manifestes dirigée par Julie Enckell Julliard et Anthony Masure
Coordination éditoriale : Sylvain Menétrey
Correctorat : Martine Passelaigue
Charte graphique de la collection : Dimitri Broquard
Design graphique : Alicia Dubuis
Polices de caractères : ABC Whyte (Dinamo, 2019), Lyon Text (Commercial Type, 2009)
Impression : Imprimerie Prestige Graphique, Plan-les-Ouates
ISBN : 978-2-940510-76-4
Dépôt légal : mars 2023

<a name="notes"></a>
### [↑](#essay) Notes

[^1]: Hugo Caselles-Dupré, Pierre Fautrel, Gauthier Vernier.
[^2]: Il en résulte une esthétique reprenant pêle-mêle le registre classique du portrait d'un clerc, les codes du non finito de la Renaissance italienne, les touches de peinture et le flou des avant-gardes, ainsi qu'une signature reproduisant un extrait du code source.
[^3]: Nous reprenons ici la formulation établie par le chercheur Alexandre Saint-Jevin dans son compte rendu de l'essai Design et humanités numériques rédigé par Anthony Masure (Saint-Jevin, 2018).
[^4]: Projet de recherche « Design et machine learning : l'automatisation au pouvoir ? », HEAD -- Genève (HES-SO), janvier -- décembre 2022, références complètes en fin d'ouvrage. Les entretiens sont indiqués dans cet essai par la référence (Mathieu, 2022).
[^5]: On doit cette distinction au mathématicien John Von Neumann. Voir : Boris Saulnier, 2003.
[^6]: Les personnalités données entre parenthèses sont, dans le détail, difficilement assignables à cette partition binaire.
[^7]: Étienne Mineur, post Facebook du 2 août 2022, http://bitly.ws/wNar
[^8]: Étienne Mineur, post Facebook du 2 août 2022, http://bitly.ws/wNar
[^9]: Gregory Chatonsky, tweet du 27 août 2022, https://twitter.com/chatonsky/status/1563544231540535296
[^10]: Site Web du projet : https://distortion.mastermediadesign.ch/Thinking%20Machines
[^11]: Merci à Pierre-Damien Huyghe de m'avoir signalé cette étymologie.
